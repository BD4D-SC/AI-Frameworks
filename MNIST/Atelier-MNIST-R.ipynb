{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance de caractères manuscrits ([MNIST](http://yann.lecun.com/exdb/mnist/)) avec <a href=\"https://cran.r-project.org/\"><img src=\"https://cran.r-project.org/Rlogo.svg\" style=\"max-width: 40px; display: inline\" alt=\"R\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objetifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'[atelier](http://wikistat.fr/pdf/st-atelier-MINST.pdf) de [wikistat](wikistat.fr) propose de comparer des versions R, python et H2O. Ce calepin décline la solution en **R**.\n",
    "\n",
    "Le site de Yann Le Cun: [MNIST DataBase](http://yann.lecun.com/exdb/mnist/), est la source des données étudiées, il  décrit précisément le problème et les modes d'acquisition. Il tient également à jour la liste des publications proposant des solutions avec la qualité de prévision obtenue. \n",
    "\n",
    "De façon très schématique, plusieurs stratégies sont développées dans une vaste littérature sur ces données.  \n",
    "* Utiliser une méthode classique (k-nn, random forest...) sans trop raffiner mais avec des temps d'apprentissage rapide conduit à un taux d'erreur un peu supérieur à 3%.\n",
    "* Ajouter  ou intégrer un pré-traitement des données permettant de recaler les images par des distorsions plus ou moins complexes.\n",
    "* Construire une mesure de distance adaptée au problème, par exemple invariante par rotation, translation, puis l'intégrer dans une technique d'apprentissage classique. \n",
    "* Utiliser une méthode plus flexibles (réseau de neurones \"profond\", scattering) avec une optimisation fine des paramètres. \n",
    "* ...\n",
    "\n",
    "L'**objectif** de ce calepin n'est pas de minimiser le taux d'erreur avec des méthodes sophistiquées mais d'utiliser ces données relativement volumineuses pour comparer diverses implémentations des méthodes d'apprentissage classiques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Lecture des données d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>60000</li>\n",
       "\t<li>785</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 60000\n",
       "\\item 785\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 60000\n",
       "2. 785\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 60000   785"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Après avoir téléchargé les données\n",
    "# Fichier train.csv\n",
    "# Lecture des données \n",
    "Dtrain=read.csv(\"mnist_train.csv\",header=F)\n",
    "dim(Dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ltrain=as.factor(Dtrain[,785])\n",
    "Dtrain=Dtrain[,-785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Même chose avex les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>10000</li>\n",
       "\t<li>784</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 10000\n",
       "\\item 784\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 10000\n",
       "2. 784\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 10000   784"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dtest=read.csv(\"mnist_test.csv\",header=F)\n",
    "Ltest=as.factor(Dtest[,785])\n",
    "Dtest=Dtest[,-785]\n",
    "dim(Dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données ont déjà été normalisées centrées et ne présentent et sont complètes. Elles ne nécessitent pas d'autre \"nettoyage\" au moins rudimentaire.\n",
    "\n",
    "Le [tutoriel](http://wikistat.fr/pdf/st-tutor3-python-scikit.pdf) d'introduction à Scikit-learn montre comment représenter les images des caractères ainsi qu'une ACP qui n'est pas reprise ici. \n",
    "\n",
    "On s'intéresse aux  performances de l'implémentation de k-means en R sur un tel volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      ": did not converge in 50 iterations"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 1.073828 mins"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=Sys.time()\n",
    "# Problème de convergence selon l'algorithme utilisé\n",
    "clas.dig=kmeans(Dtrain,10, algorithm=\"Forgy\",iter.max=50)\n",
    "t2=Sys.time()\n",
    "# temps d'exécution\n",
    "difftime(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      classe\n",
       "Ltrain    1    2    3    4    5    6    7    8    9   10\n",
       "     0   28    1 3842  222 1597   18  152   12   40   11\n",
       "     1   73    5    0   10    3 6594   11    9   12   25\n",
       "     2  227   93   32  299  143  701  177   26  150 4110\n",
       "     3  658   39   21 3859  786  421   38   25  153  131\n",
       "     4   15    7    9    0   24  194   98 2854 2612   29\n",
       "     5  508   23   48 1868 1432  714   82  434  308    4\n",
       "     6   16    0   74   27  533  451 4637   11   89   80\n",
       "     7   89 4234   11    5   10  472    4  271 1132   37\n",
       "     8 3525   20   30 1121  148  557   40  197  173   40\n",
       "     9   68  199   34  100   12  234    6 2891 2391   14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe=clas.dig$cluster\n",
    "# Homogénéité des classes\n",
    "table(Ltrain, classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Apprentissage et prévision du test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester ensuite différents modèles de discrimination. Bien entendu, il s'agirait d'optimiser les paramètres des modèles mais en prévoyant de restreindre la taille de l'échantillon d'apprentissage lorque les temps de calcul sont importants..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 $K$ plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les exécutions sont proposés sur un sous échantillon de l'échantillon d'apprentissage initial. Estimer le temps d'exécution sur tout l'échantillon ou l'obtenir ... de nuit!\n",
    "\n",
    "La complexité de l'algorithme $k$-nn est en $O(nkd)$ où $d$ est la dimension, $k$, le nombre de voisins et $n$ la taille de l'échantillon d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>12000</li>\n",
       "\t<li>784</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 12000\n",
       "\\item 784\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 12000\n",
       "2. 784\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 12000   784"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sous échantillonnage\n",
    "set.seed(11)\n",
    "SousEch=sample(1:nrow(Dtrain),nrow(Dtrain)/5)\n",
    "EchDtrain=Dtrain[SousEch,]\n",
    "EchLtrain=Ltrain[SousEch]\n",
    "dim(EchDtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time difference of 39.75309 mins"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library(class)\n",
    "t1=Sys.time() \n",
    "prev.knn=knn(EchDtrain,Dtest,EchLtrain,k=10)\n",
    "t2=Sys.time()\n",
    "difftime(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Ltest\n",
       "prev.knn    0    1    2    3    4    5    6    7    8    9\n",
       "       0  970    0   21    0    1    3    8    0   12    9\n",
       "       1    1 1129   27    4   16    6    5   39    8    8\n",
       "       2    1    2  936    3    0    0    0    2    4    2\n",
       "       3    0    1   10  964    0   22    0    1   26    6\n",
       "       4    0    0    2    1  924    3    3    2    9   11\n",
       "       5    2    0    0   15    0  833    3    0   21    1\n",
       "       6    5    3    4    0    7   13  939    0    2    1\n",
       "       7    1    0   23   11    1    3    0  964    9   20\n",
       "       8    0    0    9    6    0    2    0    0  874    1\n",
       "       9    0    0    0    6   33    7    0   20    9  950"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrice de confusion\n",
    "conf=table(prev.knn,Ltest)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0517"
      ],
      "text/latex": [
       "0.0517"
      ],
      "text/markdown": [
       "0.0517"
      ],
      "text/plain": [
       "[1] 0.0517"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taux d'erreur\n",
    "(sum(conf)-sum(diag(conf)))/sum(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme random forest de la librairie `randomForest` est implémenté en fortran puis interfacé avec R. Il se montre plus efficace que celle de $k$-nn mais nettement plus long que l'implémentation de la librairie `ranger` par [Wright et Ziegler (2015)](http://arxiv.org/pdf/1508.04409v1.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `randomForest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time difference of 57.99853 mins"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Forest avec sous-échantillon\n",
    "library(randomForest)\n",
    "t1=Sys.time() \n",
    "rf.fit=randomForest(x=EchDtrain,y=EchLtrain,xtest=Dtest,ytest=Ltest,ntree=100)\n",
    "# mtry par défaut (sqrt(p))\n",
    "t2=Sys.time()\n",
    "difftime(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Test:</strong> 0.0287"
      ],
      "text/latex": [
       "\\textbf{Test:} 0.0287"
      ],
      "text/markdown": [
       "**Test:** 0.0287"
      ],
      "text/plain": [
       "  Test \n",
       "0.0287 "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit$test$err.rate[100,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ranger`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même calcul avec l'échantillon complet mais en utilisant l'implémentation de \"ranger\". Seul souci, la parallélisation (*multithreading*) n'est pas possible sous Windows alors qu'elle est automatique avec un autre système. Le temps d'apprentissage pourrait être encore sensiblement amélioré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      ": package 'ranger' was built under R version 3.2.5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing trees.. Progress: 34%. Estimated remaining time: 1 minute, 0 seconds.\n",
      "Growing trees.. Progress: 66%. Estimated remaining time: 31 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 1.642127 mins"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library(ranger)\n",
    "t1=Sys.time() \n",
    "DataF=data.frame(\"Ltrain\"=Ltrain,Dtrain)\n",
    "rf.fit=ranger(Ltrain~.,data=DataF,num.trees=100,write.forest=TRUE)\n",
    "# mtry par défaut (sqrt(p)) \n",
    "t2=Sys.time()\n",
    "difftime(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.031\n"
     ]
    }
   ],
   "source": [
    "predY=predict(rf.fit,dat=Dtest)\n",
    "predY$class\n",
    "conf=table(predY$predictions,Ltest)\n",
    "erreur=(sum(as.vector(conf))-sum(diag(conf)))/nrow(Dtest)\n",
    "print(erreur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Effet de la taille de l'échantillon d'apprentissage avec `ranger`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La procédure d'estimation du modèle puis de prévision de l'échantillon test est itérée en fonction de la taille croissante de l'échantillon d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing trees.. Progress: 67%. Estimated remaining time: 15 seconds.\n",
      "Growing trees.. Progress: 48%. Estimated remaining time: 33 seconds.\n",
      "Growing trees.. Progress: 97%. Estimated remaining time: 2 seconds.\n",
      "Growing trees.. Progress: 37%. Estimated remaining time: 53 seconds.\n",
      "Growing trees.. Progress: 72%. Estimated remaining time: 24 seconds.\n",
      "Growing trees.. Progress: 26%. Estimated remaining time: 1 minute, 26 seconds.\n",
      "Growing trees.. Progress: 56%. Estimated remaining time: 47 seconds.\n",
      "Growing trees.. Progress: 86%. Estimated remaining time: 14 seconds.\n",
      "Growing trees.. Progress: 26%. Estimated remaining time: 1 minute, 30 seconds.\n",
      "Growing trees.. Progress: 50%. Estimated remaining time: 1 minute, 3 seconds.\n",
      "Growing trees.. Progress: 75%. Estimated remaining time: 31 seconds.\n",
      "Growing trees.. Progress: 22%. Estimated remaining time: 1 minute, 49 seconds.\n",
      "Growing trees.. Progress: 44%. Estimated remaining time: 1 minute, 17 seconds.\n",
      "Growing trees.. Progress: 64%. Estimated remaining time: 51 seconds.\n",
      "Growing trees.. Progress: 85%. Estimated remaining time: 22 seconds.\n",
      "Growing trees.. Progress: 18%. Estimated remaining time: 2 minutes, 21 seconds.\n",
      "Growing trees.. Progress: 36%. Estimated remaining time: 1 minute, 53 seconds.\n",
      "Growing trees.. Progress: 54%. Estimated remaining time: 1 minute, 20 seconds.\n",
      "Growing trees.. Progress: 72%. Estimated remaining time: 48 seconds.\n",
      "Growing trees.. Progress: 91%. Estimated remaining time: 15 seconds.\n",
      "Growing trees.. Progress: 16%. Estimated remaining time: 2 minutes, 38 seconds.\n",
      "Growing trees.. Progress: 32%. Estimated remaining time: 2 minutes, 9 seconds.\n",
      "Growing trees.. Progress: 49%. Estimated remaining time: 1 minute, 38 seconds.\n",
      "Growing trees.. Progress: 65%. Estimated remaining time: 1 minute, 6 seconds.\n",
      "Growing trees.. Progress: 82%. Estimated remaining time: 35 seconds.\n",
      "Growing trees.. Progress: 97%. Estimated remaining time: 5 seconds.\n",
      "Growing trees.. Progress: 15%. Estimated remaining time: 2 minutes, 58 seconds.\n",
      "Growing trees.. Progress: 30%. Estimated remaining time: 2 minutes, 24 seconds.\n",
      "Growing trees.. Progress: 46%. Estimated remaining time: 1 minute, 52 seconds.\n",
      "Growing trees.. Progress: 61%. Estimated remaining time: 1 minute, 21 seconds.\n",
      "Growing trees.. Progress: 76%. Estimated remaining time: 49 seconds.\n",
      "Growing trees.. Progress: 91%. Estimated remaining time: 19 seconds.\n",
      "Growing trees.. Progress: 14%. Estimated remaining time: 3 minutes, 16 seconds.\n",
      "Growing trees.. Progress: 27%. Estimated remaining time: 2 minutes, 52 seconds.\n",
      "Growing trees.. Progress: 40%. Estimated remaining time: 2 minutes, 18 seconds.\n",
      "Growing trees.. Progress: 54%. Estimated remaining time: 1 minute, 46 seconds.\n",
      "Growing trees.. Progress: 68%. Estimated remaining time: 1 minute, 15 seconds.\n",
      "Growing trees.. Progress: 81%. Estimated remaining time: 43 seconds.\n",
      "Growing trees.. Progress: 95%. Estimated remaining time: 12 seconds.\n",
      "      Taille     Temps Erreur\n",
      " [1,]   5000 13.888794 0.0545\n",
      " [2,]  10000 30.269731 0.0454\n",
      " [3,]  15000 47.969744 0.0419\n",
      " [4,]  20000  1.115497 0.0384\n",
      " [5,]  25000  1.506503 0.0359\n",
      " [6,]  30000  1.851889 0.0334\n",
      " [7,]  35000  2.154007 0.0341\n",
      " [8,]  40000  2.559163 0.0320\n",
      " [9,]  45000  2.997405 0.0320\n",
      "[10,]  50000  3.335274 0.0298\n",
      "[11,]  55000  3.595056 0.0287\n",
      "[12,]  60000  4.010846 0.0283\n"
     ]
    }
   ],
   "source": [
    "ntree=250\n",
    "errMat=matrix(rep(0,36),nrow=12,ncol=3 )\n",
    "dimnames(errMat)[[2]]=c(\"Taille\",\"Temps\",\"Erreur\")\n",
    "for (i in 1:12) {\n",
    "  SousEch=sample(1:60000,5000*i)\n",
    "  EchDtrain=Dtrain[SousEch,]\n",
    "  EchLtrain=Ltrain[SousEch]\n",
    "  n=dim(EchDtrain)\n",
    "  t1=Sys.time() \n",
    "  DataF=data.frame(\"Ltrain\"=EchLtrain,EchDtrain)\n",
    "  rf.fit=ranger(Ltrain~.,data=DataF,num.trees=ntree,write.forest=TRUE)\n",
    "  t2=Sys.time()\n",
    "  errMat[i,1]=5000*i\n",
    "  errMat[i,2]=difftime(t2,t1)\n",
    "  predY=predict(rf.fit,dat=Dtest)\n",
    "  conf=table(predY$predictions,Ltest)\n",
    "  errMat[i,3]=(sum(as.vector(conf))-sum(diag(conf)))/nrow(Dtest)\n",
    "}\n",
    "print(errMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
