{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies des grosses data](https://github.com/wikistat/Ateliers-Big-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Reconnaissance de caractères manuscrits](https://github.com/wikistat/Ateliers-Big-Data/2-MNIST) ([MNIST](http://yann.lecun.com/exdb/mnist/)) par apprentissage épais (*deep learning*) avec <a href=\"https://www.tensorflow.org/\"><img src=\"https://avatars0.githubusercontent.com/u/15658638?s=200&v=4\" style=\"max-width: 30px; display: inline\" alt=\"TensorFlow\"/></a> tensorflow et <a href=\"https://keras.io/\"><img src=\"https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png\" style=\"max-width: 100px; display: inline\" alt=\"Keras\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résumé\n",
    "\n",
    "## 1  Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objectif\n",
    "Ce calepin reprend le même objectif que les calepins de l'[Atelier MNIST](https://github.com/wikistat/Ateliers-Big-Data/tree/master/2-MNIST) et sur les mêmes données mais en utilisant cette fois les librairies `Keras` et `TensorFlow` pour aborder l'apprentissage profond. Il est une adpatation du tutoriel de Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import keras.utils as ku\n",
    "import keras.models as km\n",
    "import keras.layers as kl\n",
    "import keras.optimizers as ko\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Lecture des données d'apprentissage et de test\n",
    "\n",
    "Les données peuvent être préalablement téléchargées ou directement lues. Ce sont celles originales du site [MNIST DataBase](http://yann.lecun.com/exdb/mnist/) mais préalablement converties au format .csv, certes plus volumineux mais plus facile à lire. Attention le fichier `mnist_train.zip` présent dans le dépôt est compressé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture des données d'apprentissage\n",
    "N_classes = 10\n",
    "\n",
    "# path=\"\" # Si les données sont dans le répertoire courant sinon:\n",
    "path=\"/Users/bguillouet/Insa/TP_Insa/data/\"\n",
    "Dtrain=pd.read_csv(path+\"mnist_train.csv\",header=None)\n",
    "X_train = Dtrain.values[:,:-1]\n",
    "Y_train = Dtrain.values[:,-1]\n",
    "\n",
    "Dtest=pd.read_csv(path+\"mnist_test.csv\",header=None)\n",
    "X_test = Dtest.values[:,:-1]\n",
    "Y_test = Dtest.values[:,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Attention*, avec Keras, la variable réponse doit être une matrice binaire où chaque classe est représentée par une indicatrice: pour chaque individu, l'élément de la colone correspondant à la classe à laquelle il appartient est à 1, sinon il est à 0. \n",
    "\n",
    "Keras possède une fonction `to_catergorical` permettant de convertir directement le vecteur variable `Y_train` de réponse en matrice (`array numpy`) indicatrice`Y_train_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train_cat = ku.to_categorical(Y_train, N_classes)\n",
    "Y_test_cat = ku.to_categorical(Y_test, N_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Apprentissage et prévision du test\n",
    "\n",
    "### 2.1 Perceptron\n",
    "Première tentative d'appliquer un réseaux de neurone de type Perceptron classique avec 4 couches: \n",
    "* Dense: 52 neurones + Foncton d'activation *relu*\n",
    "* *Dropout*: 20% des neurones tiré aléatoirement sont desactivés\n",
    "* Dense: 52 neurones + Foncton d'activation *relu*\n",
    "* *Dropout*: 20% des neurones tiré aléatoirement sont desactivés\n",
    "\n",
    "Une dernière couche *softmax* fournit la classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s - loss: 14.5255 - acc: 0.0987 - val_loss: 14.5740 - val_acc: 0.0958\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s - loss: 14.5240 - acc: 0.0988 - val_loss: 14.5482 - val_acc: 0.0974\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s - loss: 14.5458 - acc: 0.0976 - val_loss: 14.5482 - val_acc: 0.0974\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s - loss: 14.5463 - acc: 0.0975 - val_loss: 14.5482 - val_acc: 0.0974\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s - loss: 14.4683 - acc: 0.1023 - val_loss: 13.7643 - val_acc: 0.1454\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s - loss: 12.8730 - acc: 0.2009 - val_loss: 11.7106 - val_acc: 0.2731\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s - loss: 11.7394 - acc: 0.2714 - val_loss: 11.9208 - val_acc: 0.2603\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 34s - loss: 11.7117 - acc: 0.2732 - val_loss: 12.0752 - val_acc: 0.2508\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s - loss: 11.6612 - acc: 0.2764 - val_loss: 11.5846 - val_acc: 0.2812\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 7s - loss: 11.6168 - acc: 0.2792 - val_loss: 11.5674 - val_acc: 0.2823\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s - loss: 11.7006 - acc: 0.2739 - val_loss: 12.0143 - val_acc: 0.2545\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s - loss: 11.8940 - acc: 0.2619 - val_loss: 11.3910 - val_acc: 0.2932\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s - loss: 11.2033 - acc: 0.3046 - val_loss: 11.2553 - val_acc: 0.3015\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s - loss: 10.8431 - acc: 0.3270 - val_loss: 10.5501 - val_acc: 0.3453\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s - loss: 10.5673 - acc: 0.3440 - val_loss: 10.0979 - val_acc: 0.3730\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s - loss: 10.0978 - acc: 0.3730 - val_loss: 9.5968 - val_acc: 0.4044\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s - loss: 9.6592 - acc: 0.4004 - val_loss: 9.3157 - val_acc: 0.4220\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s - loss: 9.4829 - acc: 0.4114 - val_loss: 9.2939 - val_acc: 0.4229\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s - loss: 9.4084 - acc: 0.4161 - val_loss: 9.9014 - val_acc: 0.3852\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 6s - loss: 9.5319 - acc: 0.4084 - val_loss: 9.4102 - val_acc: 0.4160\n"
     ]
    }
   ],
   "source": [
    "# Paramètres\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "# Définition du réseau\n",
    "model = km.Sequential()\n",
    "model.add(kl.Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.Dense(512, activation='relu'))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.Dense(N_classes, activation='softmax'))\n",
    "# Réumé\n",
    "model.summary()\n",
    "# apprentissage\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=ko.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "ts = time.time()\n",
    "history = model.fit(X_train, Y_train_cat,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test_cat))\n",
    "te = time.time()\n",
    "t_train_mpl = te-ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont assez médiocres puisque l'on obtient seulement 20% d'images bien classées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 9.41022881012\n",
      "Test accuracy: 0.416\n",
      "Time Running: 156.66 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>811</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>836</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>73</td>\n",
       "      <td>424</td>\n",
       "      <td>0</td>\n",
       "      <td>458</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>778</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>836</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>18</td>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>107</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3    4    5    6  7    8    9\n",
       "0  0  0  0  0    6  811  137  0   25    1\n",
       "1  0  0  0  0    0  100  182  0  836   17\n",
       "2  0  0  0  0   55   73  424  0  458   22\n",
       "3  0  0  0  0    5  778   35  0  166   26\n",
       "4  0  0  0  0  953    1   13  0    2   13\n",
       "5  0  0  0  0   25  836   20  0    4    7\n",
       "6  0  0  0  0   64   18  874  0    2    0\n",
       "7  0  0  0  0  108   42    7  0   89  782\n",
       "8  0  0  0  0   26  107   31  0  771   39\n",
       "9  0  0  0  0  231   36    5  0   11  726"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_mpl = model.evaluate(X_test, Y_test_cat, verbose=0)\n",
    "predict_mpl = model.predict(X_test)\n",
    "print('Test loss:', score_mpl[0])\n",
    "print('Test accuracy:', score_mpl[1])\n",
    "print(\"Time Running: %.2f seconds\" %t_train_mpl )\n",
    "pd.DataFrame(confusion_matrix(Y_test, predict_mpl.argmax(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Effet de la normalisation des données\n",
    "\n",
    "Le même réseau est utilisé mais avec normalisation préalable des données en divisant par leur valeur maximale (ici 255).\n",
    "\n",
    "#### Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.2467 - acc: 0.9244 - val_loss: 0.1093 - val_acc: 0.9668\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s - loss: 0.1068 - acc: 0.9674 - val_loss: 0.0925 - val_acc: 0.9716\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s - loss: 0.0790 - acc: 0.9765 - val_loss: 0.0749 - val_acc: 0.9790\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s - loss: 0.0608 - acc: 0.9818 - val_loss: 0.0971 - val_acc: 0.9757\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s - loss: 0.0514 - acc: 0.9847 - val_loss: 0.0861 - val_acc: 0.9766\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0436 - acc: 0.9870 - val_loss: 0.0756 - val_acc: 0.9808\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0392 - acc: 0.9885 - val_loss: 0.0833 - val_acc: 0.9814\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0350 - acc: 0.9892 - val_loss: 0.0777 - val_acc: 0.9817\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0322 - acc: 0.9907 - val_loss: 0.0874 - val_acc: 0.9820\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0304 - acc: 0.9913 - val_loss: 0.1067 - val_acc: 0.9800\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0296 - acc: 0.9919 - val_loss: 0.0888 - val_acc: 0.9830\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0280 - acc: 0.9925 - val_loss: 0.0983 - val_acc: 0.9831\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0222 - acc: 0.9935 - val_loss: 0.1047 - val_acc: 0.9813\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0248 - acc: 0.9932 - val_loss: 0.0953 - val_acc: 0.9828\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0220 - acc: 0.9940 - val_loss: 0.0992 - val_acc: 0.9814\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0207 - acc: 0.9942 - val_loss: 0.1011 - val_acc: 0.9847\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0208 - acc: 0.9944 - val_loss: 0.1090 - val_acc: 0.9828\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0197 - acc: 0.9951 - val_loss: 0.1036 - val_acc: 0.9831\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s - loss: 0.0196 - acc: 0.9950 - val_loss: 0.1090 - val_acc: 0.9832\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 7s - loss: 0.0194 - acc: 0.9950 - val_loss: 0.1084 - val_acc: 0.9836\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "# Normalisation des données\n",
    "X_train_norm = X_train/255\n",
    "X_test_norm = X_test/255\n",
    "\n",
    "model = km.Sequential()\n",
    "model.add(kl.Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.Dense(512, activation='relu'))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.Dense(N_classes, activation='softmax'))\n",
    "model.summary()\n",
    "# Apprentissage\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=ko.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "ts=time.time()\n",
    "history = model.fit(X_train_norm, Y_train_cat,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test_norm, Y_test_cat))\n",
    "te=time.time()\n",
    "t_train_mpl_norm = te-ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat est cette fois de 98% d'images bien classées!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.278843138504\n",
      "Test accuracy: 0.9827\n",
      "Time Running: 129.35 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>971</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>988</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>964</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>877</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1006</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3    4    5    6     7    8    9\n",
       "0  971     1     1    0    1    1    4     0    0    1\n",
       "1    1  1128     2    0    0    0    3     0    1    0\n",
       "2    3     0  1015    1    1    0    5     4    2    1\n",
       "3    0     0     3  988    0    4    0     6    3    6\n",
       "4    1     0     1    0  964    0    6     3    0    7\n",
       "5    2     0     0    3    0  877    6     0    3    1\n",
       "6    2     2     0    0    2    3  949     0    0    0\n",
       "7    2     4     8    0    0    0    0  1006    2    6\n",
       "8   14     0     3    1    2    4    6     2  938    4\n",
       "9    0     3     1    1    6    0    1     4    2  991"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_mpl_norm = model.evaluate(X_test, Y_test_cat, verbose=0)\n",
    "predict_mpl_norm = model.predict(X_test)\n",
    "print('Test loss:', score_mpl_norm[0])\n",
    "print('Test accuracy:', score_mpl_norm[1])\n",
    "print(\"Time Running: %.2f seconds\" %t_train_mpl_norm )\n",
    "pd.DataFrame(confusion_matrix(Y_test, predict_mpl_norm.argmax(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 *Convolutional Network (ConvNet)*\n",
    "Les propriété d'invariance par translation introduites par les couches opérant une convolution des images ont un impact important sur la qualité des résultats.\n",
    "#### Réseau\n",
    "Test d'un réseau de convolution constitué de 7 couches: \n",
    "\n",
    "* Une couche de convolution 2D, avec fenêtre de taille 3x3 et une fonction d'activation *relu*\n",
    "* Une couche de convolution 2D, avec fenêtre de taille 3x3 et une fonction d'activation *relu*\n",
    "* Une couche max pooling de fenêtre 2x2\n",
    "* Une couche *dropout* où 25% des neurones sont desactivés\n",
    "* Une couche *Flatten* transforme les images $N \\times N$ en vecteurs $N^2$.\n",
    "* Une couche classique de 128 neurones\n",
    "* Une couche dropout ou 50% des neurones sont desactivés\n",
    "\n",
    "Une couche *softmax* fournit la classification\n",
    "\n",
    "#### Format des données\n",
    "\n",
    "Dans les exemples précédents. Les données était \"applaties\". Une imade de $28\\times 28=784$ pixels est considérée comme un vecteur. \n",
    "\n",
    "Pour pouvoir utiliser le principe de la convolution la structure des images est conservée. Une image n'est pas un vecteur de tailles $784\\times 1$ mais une matrice de taille $28\\times 28$. Ainsi `X_train` est réorganisée en cube ou multitableau de dimensions $60000\\times 28\\times 28$ pour être utilisé dans un réseau de convolution.\n",
    "\n",
    "Avec **Keras** `X_train` doit même être de dimensions $60000\\times 28\\times 28\\times 1$. La dernière dimension, de taille 1 peut paraitre inutile car dans le cas des données *MNIST* les pixels ne sont décrits qu'avec un seul niveau de gris. Cependant, des images couleurs en RGB sont généralement codées avec trois niveaux d'intensité (Rouge, Vert et Bleus) correspondant à la quatrième dimension comportant 3 valeurs. \n",
    "\n",
    "Noter également que l'utilisation des couches de convolution rend inutile la normalisation préalable des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_conv = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test_conv = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 169s - loss: 1.1261 - acc: 0.8267 - val_loss: 0.0979 - val_acc: 0.9721\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 165s - loss: 0.1682 - acc: 0.9522 - val_loss: 0.0590 - val_acc: 0.9817\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 161s - loss: 0.1086 - acc: 0.9693 - val_loss: 0.0457 - val_acc: 0.9862\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 101s - loss: 0.0793 - acc: 0.9763 - val_loss: 0.0383 - val_acc: 0.9881\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 99s - loss: 0.0679 - acc: 0.9803 - val_loss: 0.0333 - val_acc: 0.9888\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 99s - loss: 0.0591 - acc: 0.9831 - val_loss: 0.0310 - val_acc: 0.9898\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 102s - loss: 0.0513 - acc: 0.9848 - val_loss: 0.0351 - val_acc: 0.9889\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 100s - loss: 0.0447 - acc: 0.9860 - val_loss: 0.0316 - val_acc: 0.99029\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 102s - loss: 0.0437 - acc: 0.9867 - val_loss: 0.0295 - val_acc: 0.9908\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 99s - loss: 0.0377 - acc: 0.9885 - val_loss: 0.0332 - val_acc: 0.9907\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 103s - loss: 0.0375 - acc: 0.9886 - val_loss: 0.0430 - val_acc: 0.9902\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 103s - loss: 0.0369 - acc: 0.9894 - val_loss: 0.0392 - val_acc: 0.9904\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 99s - loss: 0.0347 - acc: 0.9902 - val_loss: 0.0420 - val_acc: 0.9900\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 99s - loss: 0.0343 - acc: 0.9902 - val_loss: 0.0453 - val_acc: 0.9906\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 104s - loss: 0.0342 - acc: 0.9899 - val_loss: 0.0383 - val_acc: 0.9914\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 107s - loss: 0.0320 - acc: 0.9909 - val_loss: 0.0339 - val_acc: 0.9908\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 104s - loss: 0.0327 - acc: 0.9909 - val_loss: 0.0365 - val_acc: 0.9913\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 104s - loss: 0.0313 - acc: 0.9915 - val_loss: 0.0362 - val_acc: 0.9898\n",
      "Epoch 19/20\n",
      "16128/60000 [=======>......................] - ETA: 71s - loss: 0.0261 - acc: 0.9921"
     ]
    }
   ],
   "source": [
    "# descrition du réseau\n",
    "model = km.Sequential()\n",
    "model.add(kl.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28, 1), data_format=\"channels_last\"))\n",
    "model.add(kl.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(kl.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(kl.Dropout(0.25))\n",
    "model.add(kl.Flatten())\n",
    "model.add(kl.Dense(128, activation='relu'))\n",
    "model.add(kl.Dropout(0.5))\n",
    "model.add(kl.Dense(N_classes, activation='softmax'))\n",
    "# Résumé\n",
    "model.summary()\n",
    "# Apprentissage\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=ko.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "ts=time.time()\n",
    "model.fit(X_train_conv, Y_train_cat,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_conv, Y_test_cat))\n",
    "te=time.time()\n",
    "t_train_conv = te-ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_conv = model.evaluate(X_test_conv, Y_test_cat, verbose=0)\n",
    "predict_conv = model.predict(X_test_conv)\n",
    "print('Test loss:', score_conv[0])\n",
    "print('Test accuracy:', score_conv[1])\n",
    "print(\"Time Running: %.2f seconds\" %t_train_conv )\n",
    "pd.DataFrame(confusion_matrix(Y_test, predict_conv.argmax(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Commenter les résultats. Comparer avec les autres techniques d'apprentissage.\n",
    "\n",
    "**Q** Comment améliorer encore ces résultats?"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [DeepLearning]",
   "language": "python",
   "name": "Python [DeepLearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
