{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IA Framework.\n",
    "## Lab 1  - Introduction to Pyspark.\n",
    "#### Part 2 Basic Statistics and Logistic Regression with <a href=\"http://spark.apache.org/\"><img src=\"http://spark.apache.org/images/spark-logo-trademark.png\" style=\"max-width: 100px; display: inline\" alt=\"Spark\"/> </a> and  [MLlib](https://spark.apache.org/mllib/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resume**: This notebook continue the introduction to [Spark](https://spark.apache.org/) trough  [`PySpark`](http://spark.apache.org/docs/latest/api/python/) API. We will see how to sample RDD, an introduction to the MlLib library, descriptive statistics and basic uni and multi dimensionals statisticsK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context and Dataset\n",
    "\n",
    "This notebook will continue to used  [KDD Cup 1999](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=\"\" \n",
    "data_file = DATA_PATH+\"kddcup.data_10_percent.gz\"\n",
    "raw_data = sc.textFile(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD's sampling\n",
    "They are two  `function` available for sampling a RDD in spark.* `sample` and `takeSample`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_sample = raw_data.takeSample(False, 4000, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_sample = raw_data.sample(False, 0.1, seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What is the difference between these two function? Are the sample identic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the `sample` will allow to quickly estimate some value on a subsample of a huge dataset.\n",
    "\n",
    "In the celss below, we estimate the rate if normal interaction on the sample and on the all dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "raw_data_sample_items = raw_data_sample.map(lambda x: x.split(\",\"))\n",
    "sample_size = raw_data_sample.count()\n",
    "sample_normal_tags = raw_data_sample_items.filter(lambda x: \"normal.\" in x)\n",
    "t0 = time.time()\n",
    "sample_normal_tags_count = sample_normal_tags.count()\n",
    "tt = time.time() - t0\n",
    "sample_normal_ratio = sample_normal_tags_count / float(sample_size)\n",
    "print(\"Normal interaction rate is {}\".format(round(sample_normal_ratio,3)))\n",
    "print(\"Running time: {} secondes\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même chose sans échantillonnage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_items = raw_data.map(lambda x: x.split(\",\"))\n",
    "total_size = raw_data.count()\n",
    "normal_tags = raw_data_items.filter(lambda x: \"normal.\" in x)\n",
    "t0 = time.time()\n",
    "normal_tags_count = normal_tags.count()\n",
    "tt = time.time() - t0\n",
    "normal_ratio = normal_tags_count / float(total_size)\n",
    "print(\"Normal interaction rate is {}\".format(round(sample_normal_ratio,3)))\n",
    "print(\"Running time: {} secondes\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seule la phase d'échantillonnage est distribuée / parallélisée, cette procédure prend plus de temps sur un cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data munging\n",
    "As describe in the python [tutoriel](https://github.com/wikistat/Intro-Python) dedicated to data munging with `pandas`, data preprocessing is a essential part before analysis and modelling the data. Extraction, filtering, sampling, data completion, correction, anomaly detection, normalization, features selection, matching, ect.. \n",
    "\n",
    "Most of this step are unidimensional and can be easily distributed.\n",
    "\n",
    "\n",
    "### [MLlib](http://spark.apache.org/docs/latest/ml-guide.html)\n",
    "\n",
    "\n",
    "*MLlib* is a RDD-based library.  \n",
    "Another library, *SparkML* is developed by Spark and is based on DataFrame (see part 3).\n",
    "\n",
    "*SparkML* will soon completly replace *MlLib* library, but so far, some functionnalities (especially for basic statistics) are available only on MLlib.\n",
    "This two library will coexist untill spark 3 is released.\n",
    "\n",
    "The only up-to-date documentation is the official online [documentation](https://spark.apache.org/docs/latest/mllib-guide.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first build a RDD that contains only numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def parse_interaction(line):\n",
    "    line_split = line.split(\",\")\n",
    "    # keep just numeric and logical values\n",
    "    symbolic_indexes = [1,2,3,41]\n",
    "    clean_line_split = [item for i,item in enumerate(line_split) if i not in symbolic_indexes]\n",
    "    return np.array([float(x) for x in clean_line_split])\n",
    "\n",
    "vector_data = raw_data.map(parse_interaction)\n",
    "vector_data.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistics\n",
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`colStats`](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.stat.Statistics.colStats)' MLlib function enable to compute unidimensionals statistics for each columns of the `RDD[Vector]`. It returns a[`MultivariateStatisticalSummary`](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.stat.MultivariateStatisticalSummary) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "from math import sqrt \n",
    "\n",
    "# Compute column summary statistics.\n",
    "summary = Statistics.colStats(vector_data)\n",
    "\n",
    "print(\"Statistique des durées\")\n",
    "print(\" Moyenne: {}\".format(round(summary.mean()[0],3)))\n",
    "print(\" Ecart type: {}\".format(round(sqrt(summary.variance()[0]),3)))\n",
    "print(\" Valeur max: {}\".format(round(summary.max()[0],3)))\n",
    "print(\" Valeur min: {}\".format(round(summary.min()[0],3)))\n",
    "print(\" Nombre de valeurs: {}\".format(summary.count()))\n",
    "print(\" Nombre de valeurs non nulles: {}\".format(summary.numNonzeros()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_interaction_with_key(line):\n",
    "    line_split = line.split(\",\")\n",
    "    # keep just numeric and logical values\n",
    "    symbolic_indexes = [1,2,3,41]\n",
    "    clean_line_split = [item for i,item in enumerate(line_split) if i not in symbolic_indexes]\n",
    "    return (line_split[41], np.array([float(x) for x in clean_line_split]))\n",
    "\n",
    "def summary_by_label(raw_data, label):\n",
    "    label_vector_data = raw_data.map(parse_interaction_with_key).filter(lambda x: x[0]==label)\n",
    "    return Statistics.colStats(label_vector_data.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sum = summary_by_label(raw_data, \"normal.\")\n",
    "\n",
    "print(\"Duration Statistics for label: {}\".format(\"normal\"))\n",
    "print(\" Mean: {}\".format(normal_sum.mean()[0],3))\n",
    "print(\" St. deviation: {}\".format(round(sqrt(normal_sum.variance()[0]),3)))\n",
    "print(\" Max value: {}\".format(round(normal_sum.max()[0],3)))\n",
    "print(\" Min value: {}\".format(round(normal_sum.min()[0],3)))\n",
    "print(\" Total value count: {}\".format(normal_sum.count()))\n",
    "print(\" Number of non-zero values: {}\".format(normal_sum.numNonzeros()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For all label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"back.\",\"buffer_overflow.\",\"ftp_write.\",\"guess_passwd.\",\n",
    "              \"imap.\",\"ipsweep.\",\"land.\",\"loadmodule.\",\"multihop.\",\n",
    "              \"neptune.\",\"nmap.\",\"normal.\",\"perl.\",\"phf.\",\"pod.\",\"portsweep.\",\n",
    "              \"rootkit.\",\"satan.\",\"smurf.\",\"spy.\",\"teardrop.\",\"warezclient.\",\n",
    "              \"warezmaster.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_by_label =[(label, summary_by_label(raw_data, label)) for label in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Display results with `pandas`.\n",
    "def get_variable_stats_df(stats_by_label, column_i):\n",
    "    column_stats_by_label = [\n",
    "        (stat[0], np.array([float(stat[1].mean()[column_i]), float(sqrt(stat[1].variance()[column_i])), float(stat[1].min()[column_i]), float(stat[1].max()[column_i]), int(stat[1].count())])) \n",
    "        for stat in stats_by_label\n",
    "    ]\n",
    "    return pd.DataFrame.from_items(column_stats_by_label, columns=[\"Mean\", \"Std Dev\", \"Min\", \"Max\", \"Count\"], orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duration statistics, by label\")\n",
    "get_variable_stats_df(stats_by_label,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"src_bytes statistics, by label\")\n",
    "get_variable_stats_df(stats_by_label,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "`corr` allow Spearman (rangs) and Pearson correlation computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics \n",
    "correlation_matrix = Statistics.corr(vector_data, method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "col_names = [\"duration\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\n",
    "             \"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\",\"num_compromised\",\n",
    "             \"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\n",
    "             \"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "             \"is_hot_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "             \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "             \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "             \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "             \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "             \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\"]\n",
    "\n",
    "corr_df = pd.DataFrame(correlation_matrix, index=col_names, columns=col_names)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une variable bouléenne est True en cas de forte corrélation\n",
    "highly_correlated_df = (abs(corr_df) > .8) & (corr_df < 1.0)\n",
    "# Extraction des noms des variables\n",
    "correlated_vars_index = (highly_correlated_df==True).any()\n",
    "correlated_var_names = correlated_vars_index[correlated_vars_index==True].index\n",
    "highly_correlated_df.loc[correlated_var_names,correlated_var_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warnings**: [J. A. Dianes](https://github.com/jadianes/spark-py-notebooks/blob/master/nb8-mllib-logit/nb8-mllib-logit.ipynb) use the previous function to select the features according to their correlation befire using them in logisticRegression.\n",
    "This procedure is not recommended in Machine learning. It's better to used step-by-step method (*forward, backward, both*) and select the variable according to AIC or BIC criteria or using Lasso penalization. This is what is implemented in MLlib library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data.\n",
    "\n",
    "We will now use the complete [KDD cup 1999](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) dataset. If you have memory issue, restart the kernal and start from here. You can also sample the data to make it run on a smallest dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "ft = urllib.request.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz\", DATA_PATH+\"data.gz\")\n",
    "train_data_file = DATA_PATH+\"data.gz\"\n",
    "train_raw_data = sc.textFile(train_data_file)\n",
    "\n",
    "print(\"Train data size is {}\".format(train_raw_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = urllib.request.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/corrected.gz\", DATA_PATH+\"corrected.gz\")\n",
    "test_data_file = DATA_PATH+\"corrected.gz\"\n",
    "test_raw_data = sc.textFile(test_data_file)\n",
    "\n",
    "print(\"Test data size is {}\".format(test_raw_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform learning, you have to convert the data in the **Labeled Points** format.\n",
    "This object take the input and the features as an input.\n",
    "We define a function to convert the raw line to a LabeledPoint object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "def parse_interaction(line):\n",
    "    line_split = line.split(\",\")\n",
    "    clean_line_split = line_split[0:1]+line_split[4:41]\n",
    "    attack = 1.0\n",
    "    if line_split[41]=='normal.':\n",
    "        attack = 0.0\n",
    "    return LabeledPoint(attack, array([float(x) for x in clean_line_split]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.map(parse_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_raw_data.map(parse_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Learning the model\n",
    "Training the model is basically the same than with scikit learn.\n",
    "Mllib propose two optimization [algorithms](https://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression)  (*mini-batch gradient descent* and L-BFGS) L-BFGS which is supposed to run faster.\n",
    "\n",
    "As in  *Scikit-learn*, *l2* (ridge) and *l1* (lasso) are available.\n",
    "\n",
    "See full doc [here](https://spark.apache.org/docs/2.0.0/api/python/pyspark.mllib.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "t0 = time()\n",
    "logit_model = LogisticRegressionWithLBFGS.train(training_data)\n",
    "tt = time() - t0\n",
    "print(\"Apprentissage en {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Estimation\n",
    "The `map` function enable to predict the attack for each entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_and_preds = test_data.map(lambda p: (p.label, logit_model.predict(p.features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "test_accuracy = labels_and_preds.filter(lambda x: x[0] == x[1]).count() / float(test_data.count())\n",
    "erreur=1-test_accuracy\n",
    "tt = time() - t0\n",
    "print(\"Calcul en {} secondes. Le taux d'erreur est {}\".format(round(tt,3), round(erreur,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercices**\n",
    "\n",
    "- Qualitative variable such as `protocol` or `service` has been removed for simplicity. Add them as indicatrices and re-train the model.(*dummy variables*)\n",
    "- Try to [optimize](https://spark.apache.org/docs/latest/ml-tuning.html) the model with cross validation by trying various parameters.\n",
    "- Use other algorithm such as  [RandomForest](https://spark.apache.org/docs/latest/mllib-ensembles.html#random-forests) on this problem."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "457px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
