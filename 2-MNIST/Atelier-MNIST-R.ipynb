{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies des grosses data](https://github.com/wikistat/Ateliers-Big-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Reconnaissance de caractères manuscrits](https://github.com/wikistat/Ateliers-Big-Data/2-MNIST) ([MNIST](http://yann.lecun.com/exdb/mnist/)) avec <a href=\"https://cran.r-project.org/\"><img src=\"https://cran.r-project.org/Rlogo.svg\" style=\"max-width: 40px; display: inline\" alt=\"R\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objetif\n",
    "Ce calepin peut être directement exécuté si le noyau [IRkernel](https://irkernel.github.io/installation/) est bien installé pour permettre d'utiliser R.\n",
    "\n",
    "Analyse des données en R, noter les temps d'exécution, la précision estimée sur l'échantillon test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Lecture des données d'apprentissage et de test\n",
    "Les données peuvent être préalablement téléchargées ou directement lues. Ce sont celles originales du site [MNIST DataBase](http://yann.lecun.com/exdb/mnist/) mais préalablement converties au format .csv, certes plus volumineux mais plus facile à lire. Attention le fichier `mnist_train.zip` présent dans le dépôt est compressé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>60000</li>\n",
       "\t<li>785</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 60000\n",
       "\\item 785\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 60000\n",
       "2. 785\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 60000   785"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Après avoir téléchargé les données\n",
    "# Fichier train.csv\n",
    "# Lecture des données \n",
    "path=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/data/\"\n",
    "# path=\"\"\n",
    "Dtrain=read.csv(paste(path,\"mnist_train.csv\",sep=\"\"),header=F)\n",
    "dim(Dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variable Label\n",
    "Ltrain=as.factor(Dtrain[,785])\n",
    "Dtrain=Dtrain[,-785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>10000</li>\n",
       "\t<li>784</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 10000\n",
       "\\item 784\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 10000\n",
       "2. 784\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 10000   784"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Même chose avec les données de test\n",
    "Dtest=read.csv(paste(path,\"mnist_test.csv\",sep=\"\"),header=F)\n",
    "Ltest=as.factor(Dtest[,785])\n",
    "Dtest=Dtest[,-785]\n",
    "dim(Dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données ont déjà été normalisées centrées et sont complètes. Elles ne nécessitent pas d'autre \"nettoyage\" au moins rudimentaire.\n",
    "\n",
    "Le [tutoriel](http://wikistat.fr/pdf/st-tutor3-python-scikit.pdf) d'introduction à Scikit-learn montre comment représenter les images des caractères ainsi qu'une ACP qui n'est pas reprise ici. \n",
    "\n",
    "On s'intéresse, à titre indicatif, aux  performances de l'implémentation de *k*-means en R sur un tel volume même son utilisation n'est pas très utile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“did not converge in 50 iterations”"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 1.067892 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1=Sys.time()\n",
    "# Problème de convergence selon l'algorithme utilisé\n",
    "clas.dig=kmeans(Dtrain,10, algorithm=\"Forgy\",iter.max=50)\n",
    "t2=Sys.time()\n",
    "# temps d'exécution\n",
    "difftime(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      classe\n",
       "Ltrain    1    2    3    4    5    6    7    8    9   10\n",
       "     0  225    6 4176  161    8   50   56    3 1219   19\n",
       "     1    9 6607    0   11   39    9   17    5    9   36\n",
       "     2  272  688   41  138 4149  184  176   53  211   46\n",
       "     3 3927  350   21   37  155   90  864   27  512  148\n",
       "     4    0  220    2  102   13 2284    8 1552  120 1541\n",
       "     5 1823  438   49   80    6  216  884  118 1526  281\n",
       "     6   27  309   59 4082   64  149   23    1 1199    5\n",
       "     7    3  371   12    4   37  654   14 2729    6 2435\n",
       "     8 1027  561   26   43   41  135 3430  169  274  145\n",
       "     9   84  161   34    6    5 1569   42 1628   17 2403"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classe=clas.dig$cluster\n",
    "# Homogénéité des classes\n",
    "table(Ltrain, classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Apprentissage et prévision du test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester ensuite différents modèles de discrimination. Bien entendu, il s'agirait d'optimiser les paramètres des modèles mais en prévoyant de restreindre la taille de l'échantillon d'apprentissage lorque les temps de calcul sont importants..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 $K$ plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les exécutions sont proposés sur un sous échantillon de l'échantillon d'apprentissage initial. Estimer le temps d'exécution sur tout l'échantillon ou l'obtenir ... de nuit!\n",
    "\n",
    "La complexité de l'algorithme $k$-nn est en $O(nkd)$ où $d$ est la dimension, $k$, le nombre de voisins et $n$ la taille de l'échantillon d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>12000</li>\n",
       "\t<li>784</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 12000\n",
       "\\item 784\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 12000\n",
       "2. 784\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 12000   784"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sous échantillonnage\n",
    "set.seed(11)\n",
    "SousEch=sample(1:nrow(Dtrain),nrow(Dtrain)/5)\n",
    "EchDtrain=Dtrain[SousEch,]\n",
    "EchLtrain=Ltrain[SousEch]\n",
    "dim(EchDtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time difference of 33.97615 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(class)\n",
    "t1=Sys.time() \n",
    "prev.knn=knn(EchDtrain,Dtest,EchLtrain,k=10)\n",
    "t2=Sys.time()\n",
    "difftime(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Ltest\n",
       "prev.knn    0    1    2    3    4    5    6    7    8    9\n",
       "       0  970    0   21    0    1    3    8    0   12    9\n",
       "       1    1 1129   27    4   16    6    5   39    8    8\n",
       "       2    1    2  936    3    0    0    0    2    4    2\n",
       "       3    0    1   10  964    0   22    0    1   26    6\n",
       "       4    0    0    2    1  924    3    3    2    9   11\n",
       "       5    2    0    0   15    0  833    3    0   21    1\n",
       "       6    5    3    4    0    7   13  939    0    2    1\n",
       "       7    1    0   23   11    1    3    0  964    9   20\n",
       "       8    0    0    9    6    0    2    0    0  874    1\n",
       "       9    0    0    0    6   33    7    0   20    9  950"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matrice de confusion\n",
    "conf=table(prev.knn,Ltest)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0517"
      ],
      "text/latex": [
       "0.0517"
      ],
      "text/markdown": [
       "0.0517"
      ],
      "text/plain": [
       "[1] 0.0517"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#taux d'erreur\n",
    "(sum(conf)-sum(diag(conf)))/sum(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme random forest de la librairie `randomForest` est implémenté en fortran puis interfacé avec R. Il se montre plus efficace que celle de $k$-nn mais nettement plus long que l'implémentation de la librairie `ranger` par [Wright et Ziegler (2015)](http://arxiv.org/pdf/1508.04409v1.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `randomForest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(randomForest): there is no package called ‘randomForest’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(randomForest): there is no package called ‘randomForest’\nTraceback:\n",
      "1. library(randomForest)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "## Random Forest avec sous-échantillon\n",
    "library(randomForest)\n",
    "t1=Sys.time() \n",
    "rf.fit=randomForest(x=EchDtrain,y=EchLtrain,xtest=Dtest,ytest=Ltest,ntree=100)\n",
    "# mtry par défaut (sqrt(p))\n",
    "t2=Sys.time()\n",
    "difftime(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.fit$test$err.rate[100,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ranger`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même calcul avec l'échantillon complet mais en utilisant l'implémentation de \"ranger\". Seul souci, la parallélisation (*multithreading*) n'est pas possible sous Windows alors qu'elle est automatique avec un autre système. Le temps d'apprentissage pourrait être encore sensiblement amélioré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(ranger)\n",
    "t1=Sys.time() \n",
    "DataF=data.frame(\"Ltrain\"=Ltrain,Dtrain)\n",
    "rf.fit=ranger(Ltrain~.,data=DataF,num.trees=100,write.forest=TRUE)\n",
    "# mtry par défaut (sqrt(p)) \n",
    "t2=Sys.time()\n",
    "difftime(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predY=predict(rf.fit,dat=Dtest)\n",
    "predY$class\n",
    "conf=table(predY$predictions,Ltest)\n",
    "erreur=(sum(as.vector(conf))-sum(diag(conf)))/nrow(Dtest)\n",
    "print(erreur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Effet de la taille de l'échantillon d'apprentissage avec `ranger`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La procédure d'estimation du modèle puis de prévision de l'échantillon test est itérée en fonction de la taille croissante de l'échantillon d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntree=250\n",
    "errMat=matrix(rep(0,36),nrow=12,ncol=3 )\n",
    "dimnames(errMat)[[2]]=c(\"Taille\",\"Temps\",\"Erreur\")\n",
    "for (i in 1:12) {\n",
    "  SousEch=sample(1:60000,5000*i)\n",
    "  EchDtrain=Dtrain[SousEch,]\n",
    "  EchLtrain=Ltrain[SousEch]\n",
    "  n=dim(EchDtrain)\n",
    "  t1=Sys.time() \n",
    "  DataF=data.frame(\"Ltrain\"=EchLtrain,EchDtrain)\n",
    "  rf.fit=ranger(Ltrain~.,data=DataF,num.trees=ntree,write.forest=TRUE)\n",
    "  t2=Sys.time()\n",
    "  errMat[i,1]=5000*i\n",
    "  errMat[i,2]=difftime(t2,t1)\n",
    "  predY=predict(rf.fit,dat=Dtest)\n",
    "  conf=table(predY$predictions,Ltest)\n",
    "  errMat[i,3]=(sum(as.vector(conf))-sum(diag(conf)))/nrow(Dtest)\n",
    "}\n",
    "print(errMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Résultats \n",
    "\n",
    "Taille | Temps |Erreur\n",
    "--:|--:|--:|\n",
    "5000  | 0.14 | 0.0545\n",
    "10000 | 0.30 | 0.0454\n",
    "15000 | 0.48 | 0.0419\n",
    "20000 |  1.12 | 0.0384\n",
    "25000 |  1.51 | 0.0359\n",
    "30000 |  1.85 | 0.0334\n",
    "35000 |  2.15 | 0.0341\n",
    "40000 |  2.56 | 0.0320\n",
    "45000 |  3.00 | 0.0320\n",
    "50000 |  3.33 | 0.0298\n",
    "55000 |  3.60 | 0.0287\n",
    "60000 |  4.01 | 0.0283"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  },
  "toc": {
   "nav_menu": {
    "height": "257px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "10",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
