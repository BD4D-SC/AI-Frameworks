{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies des grosses data](https://github.com/wikistat/Ateliers-Big-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance de caractères manuscrits ([MNIST](http://yann.lecun.com/exdb/mnist/)) avec <a href=\"https://cran.r-project.org/\"><img src=\"https://cran.r-project.org/Rlogo.svg\" style=\"max-width: 40px; display: inline\" alt=\"R\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objetifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cet [atelier](https://github.com/wikistat/Ateliers-Big-Data/tree/master/MNIST) propose de comparer des versions R, Python et Spark. Ce calepin décline la solution en **R**.\n",
    "\n",
    "Le site de Yann Le Cun: [MNIST DataBase](http://yann.lecun.com/exdb/mnist/), est la source des données étudiées, il  décrit précisément le problème et les modes d'acquisition. Il tient également à jour la liste des publications proposant des solutions avec la qualité de prévision obtenue. \n",
    "\n",
    "De façon très schématique, plusieurs stratégies sont développées dans une vaste littérature sur ces données.  \n",
    "* Utiliser une méthode classique (k-nn, random forest...) sans trop raffiner mais avec des temps d'apprentissage rapide conduit à un taux d'erreur un peu supérieur à 3%.\n",
    "* Ajouter  ou intégrer un pré-traitement des données permettant de recaler les images par des distorsions plus ou moins complexes.\n",
    "* Construire une mesure de distance adaptée au problème, par exemple invariante par rotation, translation, puis l'intégrer dans une technique d'apprentissage classique. \n",
    "* Utiliser une méthode plus flexibles (réseau de neurones \"profond\", scattering) avec une optimisation fine des paramètres. \n",
    "* ...\n",
    "\n",
    "L'**objectif** de ce calepin n'est pas de minimiser le taux d'erreur avec des méthodes sophistiquées mais d'utiliser ces données relativement volumineuses pour comparer diverses implémentations des méthodes d'apprentissage classiques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Lecture des données d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Après avoir téléchargé les données\n",
    "# Fichier train.csv\n",
    "# Lecture des données \n",
    "Dtrain=read.csv(\"mnist_train.csv\",header=F)\n",
    "dim(Dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ltrain=as.factor(Dtrain[,785])\n",
    "Dtrain=Dtrain[,-785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Même chose avex les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Dtest=read.csv(\"mnist_test.csv\",header=F)\n",
    "Ltest=as.factor(Dtest[,785])\n",
    "Dtest=Dtest[,-785]\n",
    "dim(Dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données ont déjà été normalisées centrées et ne présentent et sont complètes. Elles ne nécessitent pas d'autre \"nettoyage\" au moins rudimentaire.\n",
    "\n",
    "Le [tutoriel](http://wikistat.fr/pdf/st-tutor3-python-scikit.pdf) d'introduction à Scikit-learn montre comment représenter les images des caractères ainsi qu'une ACP qui n'est pas reprise ici. \n",
    "\n",
    "On s'intéresse aux  performances de l'implémentation de k-means en R sur un tel volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1=Sys.time()\n",
    "# Problème de convergence selon l'algorithme utilisé\n",
    "clas.dig=kmeans(Dtrain,10, algorithm=\"Forgy\",iter.max=50)\n",
    "t2=Sys.time()\n",
    "# temps d'exécution\n",
    "difftime(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classe=clas.dig$cluster\n",
    "# Homogénéité des classes\n",
    "table(Ltrain, classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Apprentissage et prévision du test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester ensuite différents modèles de discrimination. Bien entendu, il s'agirait d'optimiser les paramètres des modèles mais en prévoyant de restreindre la taille de l'échantillon d'apprentissage lorque les temps de calcul sont importants..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 $K$ plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les exécutions sont proposés sur un sous échantillon de l'échantillon d'apprentissage initial. Estimer le temps d'exécution sur tout l'échantillon ou l'obtenir ... de nuit!\n",
    "\n",
    "La complexité de l'algorithme $k$-nn est en $O(nkd)$ où $d$ est la dimension, $k$, le nombre de voisins et $n$ la taille de l'échantillon d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sous échantillonnage\n",
    "set.seed(11)\n",
    "SousEch=sample(1:nrow(Dtrain),nrow(Dtrain)/5)\n",
    "EchDtrain=Dtrain[SousEch,]\n",
    "EchLtrain=Ltrain[SousEch]\n",
    "dim(EchDtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(class)\n",
    "t1=Sys.time() \n",
    "prev.knn=knn(EchDtrain,Dtest,EchLtrain,k=10)\n",
    "t2=Sys.time()\n",
    "difftime(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# matrice de confusion\n",
    "conf=table(prev.knn,Ltest)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#taux d'erreur\n",
    "(sum(conf)-sum(diag(conf)))/sum(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme random forest de la librairie `randomForest` est implémenté en fortran puis interfacé avec R. Il se montre plus efficace que celle de $k$-nn mais nettement plus long que l'implémentation de la librairie `ranger` par [Wright et Ziegler (2015)](http://arxiv.org/pdf/1508.04409v1.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `randomForest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Random Forest avec sous-échantillon\n",
    "library(randomForest)\n",
    "t1=Sys.time() \n",
    "rf.fit=randomForest(x=EchDtrain,y=EchLtrain,xtest=Dtest,ytest=Ltest,ntree=100)\n",
    "# mtry par défaut (sqrt(p))\n",
    "t2=Sys.time()\n",
    "difftime(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.fit$test$err.rate[100,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ranger`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même calcul avec l'échantillon complet mais en utilisant l'implémentation de \"ranger\". Seul souci, la parallélisation (*multithreading*) n'est pas possible sous Windows alors qu'elle est automatique avec un autre système. Le temps d'apprentissage pourrait être encore sensiblement amélioré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(ranger)\n",
    "t1=Sys.time() \n",
    "DataF=data.frame(\"Ltrain\"=Ltrain,Dtrain)\n",
    "rf.fit=ranger(Ltrain~.,data=DataF,num.trees=100,write.forest=TRUE)\n",
    "# mtry par défaut (sqrt(p)) \n",
    "t2=Sys.time()\n",
    "difftime(t2,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predY=predict(rf.fit,dat=Dtest)\n",
    "predY$class\n",
    "conf=table(predY$predictions,Ltest)\n",
    "erreur=(sum(as.vector(conf))-sum(diag(conf)))/nrow(Dtest)\n",
    "print(erreur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Effet de la taille de l'échantillon d'apprentissage avec `ranger`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La procédure d'estimation du modèle puis de prévision de l'échantillon test est itérée en fonction de la taille croissante de l'échantillon d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntree=250\n",
    "errMat=matrix(rep(0,36),nrow=12,ncol=3 )\n",
    "dimnames(errMat)[[2]]=c(\"Taille\",\"Temps\",\"Erreur\")\n",
    "for (i in 1:12) {\n",
    "  SousEch=sample(1:60000,5000*i)\n",
    "  EchDtrain=Dtrain[SousEch,]\n",
    "  EchLtrain=Ltrain[SousEch]\n",
    "  n=dim(EchDtrain)\n",
    "  t1=Sys.time() \n",
    "  DataF=data.frame(\"Ltrain\"=EchLtrain,EchDtrain)\n",
    "  rf.fit=ranger(Ltrain~.,data=DataF,num.trees=ntree,write.forest=TRUE)\n",
    "  t2=Sys.time()\n",
    "  errMat[i,1]=5000*i\n",
    "  errMat[i,2]=difftime(t2,t1)\n",
    "  predY=predict(rf.fit,dat=Dtest)\n",
    "  conf=table(predY$predictions,Ltest)\n",
    "  errMat[i,3]=(sum(as.vector(conf))-sum(diag(conf)))/nrow(Dtest)\n",
    "}\n",
    "print(errMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Résultats à mettre en forme:\n",
    "\n",
    "      Taille     Temps Erreur\n",
    " [1,]   5000 13.888794 0.0545\n",
    " [2,]  10000 30.269731 0.0454\n",
    " [3,]  15000 47.969744 0.0419\n",
    " [4,]  20000  1.115497 0.0384\n",
    " [5,]  25000  1.506503 0.0359\n",
    " [6,]  30000  1.851889 0.0334\n",
    " [7,]  35000  2.154007 0.0341\n",
    " [8,]  40000  2.559163 0.0320\n",
    " [9,]  45000  2.997405 0.0320\n",
    "[10,]  50000  3.335274 0.0298\n",
    "[11,]  55000  3.595056 0.0287\n",
    "[12,]  60000  4.010846 0.0283"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
