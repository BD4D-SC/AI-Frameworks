{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 250px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining et Catégorisation de Produits avec Python et Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Il s'agit d'une version simplifiée du concours proposé par CDiscount et paru sur le site [datascience.net](https://www.datascience.net/fr/challenge). Les données d'apprentissage sont accessibles sur demande auprès de CDiscount. Le solutions de l'échantillon test du concours ne sont pas et ne seront pas rendues publiques. Un échantillon test est donc construit pour l'usage de ce tutoriel.  L'objectif est de prévoir la catégorie d'un produit à partir de son descriptif. Seule la catégorie principale (1er niveau) est prédite au lieu des trois niveaux demandés dans le concours. L'objectif est plutôt de comparer les performances des méthodes et technologies en fonction de la taille de la base d'apprentissage ainsi que d'illustrer sur un exemple complexe le prétraitement de données textuelles. La stratégie de sous ou sur échantillonnage des catégories qui permet d'améliorer la prévision n'a pas été mise en oeuvre.\n",
    "* L'exemple est présenté sur un échantillon réduit d'un million de produits au lieu des 15M initiaux\n",
    "* L'échantillon réduit peut encore l'être puis séparé en 2 parties: apprentissage et validation. \n",
    "* Les données textuelles sont  nettoyées, racinisées, vectorisées avant modélisation.\n",
    "* Trois modélisations sont estimées: logistique, arbre, forêt aléatoire.\n",
    "* Optimiser l'erreur en faisant varier différents paramètres: types et paramètres de vectorisation (TF-IDF), paramètres de la régression logistique (pénalisation L1) et de la forêt aléatoire (nombre d'arbres et nombre de variables aléatoire).\n",
    "\n",
    "Exécuter finalement le code pour différentes tailles (paramètre tauxTot ci-dessous) de l'échantillon d'apprentissage et comparer les qualités de prévision obtenues. \n",
    "\n",
    "Deux échantillons de test ont été mis de côté et seront utilisés dans un prochain calepin (avec pyspark) pour comparer les stratégies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions nécessaires à la préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importation des librairies utilisées\n",
    "import unicodedata \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "import collections\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Définition des noms de fichier\n",
    "## Définition du répertoire de travail\n",
    "## par défaut le répertoire courant\n",
    "DATA_DIR = \"\"\n",
    "#Fichier réduit avec un million d'articles\n",
    "training_reduit_path = \"CDiscount_reduit.csv\"\n",
    "## Fichiers résultant de l'extraction apprentissage/validation\n",
    "training_reduit_train_path = DATA_DIR + \"training_reduit_train.csv\"\n",
    "training_reduit_validation_path = DATA_DIR + \"training_reduit_validation.csv\"\n",
    "## Fichiers nettoyés \n",
    "training_clean_train_path = DATA_DIR + \"training_clean_train.csv\"\n",
    "training_clean_validation_path = DATA_DIR + \"training_clean_validation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Liste des variables dans les différents fichiers d'apprentissage et de test\n",
    "HEADER_TEST = ['Description','Libelle','Marque']\n",
    "HEADER_TRAIN =['Categorie1','Categorie2','Categorie3','Description','Libelle','Marque']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Si nécessaire (première exécution) chargement de nltk, librairie pour la suppression \n",
    "## des mots d'arrêt et la racinisation\n",
    "## nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fonction pour extraire aléatoirement tauxTot lignes d'un fichier et \n",
    "## réaliser le partage aléatoire en deux sous-fichiers validation (tauxValid) \n",
    "## et apprentissage (1-tauxValid)\n",
    "def split_dataset(input_path,output_train_path,output_validation_path,tauxTot,tauxValid):\n",
    "    print(\"Split Start\")\n",
    "    random.seed(11)\n",
    "    time_start = time.time()\n",
    "    with open(input_path) as fInput:\n",
    "        with open(output_train_path, \"w\") as fTrain, open(output_validation_path, \"w\") as fValid:\n",
    "            for line in fInput:\n",
    "                if random.random() < tauxTot:\n",
    "                    fTrain.write(line) if random.random() > tauxValid else fValid.write(line)      \n",
    "    time_end = time.time()\n",
    "    print(\"Split Takes %d s\" %(time_end-time_start))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fonction clean : nettoyage préalable a l'apprentissage statistique des fichiers \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "## listes de mots à supprimer dans la description des produits\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('french')\n",
    "lucene_stopwords = [unicode(w, \"utf-8\") for w in open(DATA_DIR+\"lucene_stopwords.txt\").read().split(\",\")]\n",
    "stopwords = list(nltk_stopwords)\n",
    "## Algo de stemming permettant de supprimer automatiquement les \n",
    "## suffixes pour n'obtenir que la racine des mots.\n",
    "## On parle de racinisation.\n",
    "stemmer=nltk.stem.SnowballStemmer('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fonction de nettoyage des mots, \n",
    "## tout en minuscule, caractères spéciaux, numériques\n",
    "## racinisation\n",
    "def clean_txt(txt):\n",
    "    ### remove html stuff\n",
    "    txt = BeautifulSoup(txt,from_encoding='utf-8').get_text()\n",
    "    ### lower case\n",
    "    txt = txt.lower()\n",
    "    ### special escaping character '...'\n",
    "    txt = txt.replace(u'\\u2026','.')\n",
    "    txt = txt.replace(u'\\u00a0',' ')\n",
    "    ### remove accent btw\n",
    "    txt = unicodedata.normalize('NFD', txt).encode('ascii', 'ignore')\n",
    "    ###txt = unidecode(txt)\n",
    "    ### remove non alphanumeric char\n",
    "    txt = re.sub('[^a-z_]', ' ', txt)\n",
    "    ### remove french stop words\n",
    "    tokens = [w for w in txt.split() if (len(w)>2) and (w not in nltk_stopwords)]\n",
    "    ### french stemming\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    ### tokens = stemmer.stemWords(tokens)\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fonction de nettoyage du fichier(stemming et liste de mots à supprimer)\n",
    "def clean_file(input_path, output_path, type, columns= \n",
    "               ('Description', 'Libelle', 'Marque') , nrows = None):\n",
    "    print(\"Clean File: \" + input_path)\n",
    "    if type==\"train\":\n",
    "        header = HEADER_TRAIN\n",
    "        idx_id = 3\n",
    "    elif type == \"test\":\n",
    "        header = HEADER_TEST\n",
    "        idx_id = 0\n",
    "    else:\n",
    "        raise ValueError(\"Type should be either 'test' or 'train', not \" + type)\n",
    "    columns_idx  = [(k, v) for v,k in enumerate(header) if k in columns]\n",
    "    ff = open(output_path,'w')\n",
    "    line = ';'.join(header[:idx_id] + list(columns))\n",
    "    ff.write(line+'\\n')\n",
    "    start_time = time.time()\n",
    "    counter = 0\n",
    "    for line in open(input_path):\n",
    "        if counter==0:\n",
    "            counter+=1\n",
    "            continue\n",
    "        ls = line.split(';')\n",
    "        ls_out = ls[:idx_id]\n",
    "        for k,v in columns_idx:\n",
    "            if k ==\"Marque\":\n",
    "                txt = ls[v]\n",
    "                txt = re.sub('[^a-zA-Z0-9]', '_', txt).lower()\n",
    "                ls_out.append(txt)\n",
    "            else:\n",
    "                txt = ls[v]\n",
    "                ls_out.append(clean_txt(txt))\n",
    "        line = ';'.join(ls_out)\n",
    "        ff.write(line+'\\n')\n",
    "        counter += 1\n",
    "        if (nrows is not None) and (counter>=nrows):\n",
    "            break\n",
    "    ff.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fonction vectorizer\n",
    "## Création d’une matrice indiquant\n",
    "## les fréquences\" des mots contenus dans chaque description\n",
    "## de nombreux paramètres seraient à tester\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def vectorizer(df,columns,stop_words=None):\n",
    "    txt=np.repeat(\"\",len(df)).astype(\"object\")\n",
    "    print(txt.dtype)\n",
    "    for c in columns:\n",
    "        txt+=\" \" + df[c].values\n",
    "    vec = TfidfVectorizer(\n",
    "        min_df = 1,\n",
    "        stop_words = stop_words,\n",
    "        smooth_idf=True,\n",
    "        norm='l2',\n",
    "        sublinear_tf=True,\n",
    "        use_idf=True,\n",
    "        ngram_range=(1,2)) #bi-grams\n",
    "    X = vec.fit_transform(txt)\n",
    "    return vec,X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exécution de la préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des fichiers, nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Start\n",
      "Split Takes 0 s\n",
      "Clean File: training_reduit_train.csv\n",
      "Clean File: training_reduit_validation.csv\n"
     ]
    }
   ],
   "source": [
    "#Fichier \"main\", on procede au mélange, au partitionnage, \n",
    "## à l'échantillonnage, au nettoyage, à la vectorisation\n",
    "# Définition des taux d'échantillonnage pour fixer la taille des fichiers\n",
    "tauxTot=0.01  # part totale extraite du fichier initial ici déjà réduit\n",
    "tauxValid=0.20 # part de l'échantillon de validation\n",
    "# liste des variables prises en compte\n",
    "columns = ('Description', 'Libelle') # laisse tomber la marque\n",
    "# Extraction d'un sous-échantillon séparé en deux parties \n",
    "## apprentissage et validation\n",
    "split_dataset(training_reduit_path,training_reduit_train_path,\n",
    "                  training_reduit_validation_path, tauxTot, tauxValid)\n",
    "# nettoyage des fichiers\n",
    "clean_file(training_reduit_train_path, training_clean_train_path,\n",
    "               \"train\", columns= columns)\n",
    "clean_file(training_reduit_validation_path, training_clean_validation_path,\n",
    "               \"train\", columns= columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "# Vectorisation des données textuelles\n",
    "## Attention d'autres options de la fonction vectorizer seraient à tester à ce niveau\n",
    "## lire la base d'apprentissage\n",
    "dftrain = pd.read_csv(training_clean_train_path, sep = \";\").fillna(\"\")\n",
    "## vectorisation de l'apprentissage\n",
    "vec,X = vectorizer(dftrain, columns, None)\n",
    "Y = dftrain['Categorie1'].values\n",
    "## lire les données de validation\n",
    "dfvalid=pd.read_csv(training_clean_validation_path,sep=\";\").fillna(\"\")\n",
    "txt=np.repeat(\"\",len(dfvalid)).astype(\"object\")\n",
    "for c in columns:\n",
    "    txt+=\" \" + dfvalid[c].values\n",
    "## application de la vectorisation \n",
    "Xv=vec.transform(txt)  \n",
    "Yv=dfvalid['Categorie1'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation et performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# training score:', 0.99962316291923126)\n"
     ]
    }
   ],
   "source": [
    "# Regression Logistique \n",
    "## estimation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "cla = LogisticRegression(C=100)\n",
    "cla.fit(X,Y)\n",
    "score=cla.score(X,Y)\n",
    "print('# training score:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# validation score:', 0.86011150532184488)\n"
     ]
    }
   ],
   "source": [
    "## erreur en validation\n",
    "scoreValidation=cla.score(Xv,Yv)\n",
    "print('# validation score:',scoreValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Takes 7 s\n",
      "('# training score :', 0.99962316291923126)\n"
     ]
    }
   ],
   "source": [
    "#Méthode  CART\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "time_start = time.time()\n",
    "clf = clf.fit(X, Y)\n",
    "time_end = time.time()\n",
    "print(\"CART Takes %d s\" %(time_end-time_start) )\n",
    "score=clf.score(X,Y)\n",
    "print('# training score :',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# validation score :', 0.69285352255448551)\n"
     ]
    }
   ],
   "source": [
    "scoreValidation=clf.score(Xv,Yv)\n",
    "print('# validation score :',scoreValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Takes 15 s\n",
      "('# training score :', 0.99962316291923126)\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=-1,max_features=24)\n",
    "Y = dftrain['Categorie1'].values\n",
    "time_start = time.time()\n",
    "rf = rf.fit(X, Y)\n",
    "time_end = time.time()\n",
    "print(\"RF Takes %d s\" %(time_end-time_start) )\n",
    "score=rf.score(X,Y)\n",
    "print('# training score :',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# validation score :', 0.77749619868220987)\n"
     ]
    }
   ],
   "source": [
    "scoreValidation=rf.score(Xv,Yv)\n",
    "print('# validation score :',scoreValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
