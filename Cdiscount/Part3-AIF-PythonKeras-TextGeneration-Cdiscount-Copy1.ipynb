{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies de l'intelligence Artificielle](https://github.com/wikistat/AI-Frameworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement Naturel du Langage (NLP) : Génération de Texte avec des Réseaux Récurrent. \n",
    "\n",
    "Au cours de ce calepin, nous allons voir comment générer des description de produits à l'aide de Réseaux Récurents et notamment grace aux structure LSTM (Long-Short Term Memory). \n",
    "\n",
    "L'intérêt de cette application est limité. Les descriptions de textes de ce document sont trop pauvres syntaxiquement pour pouvoir juger réellement de la qualité du texte généré. L'intérêt réel de ce calepin est de voir comment les données doivent être mis en forme pour être utilisé dans un réseau recurrent dans un but de génération de texte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importation des librairies utilisées\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import keras.models as km\n",
    "import keras.layers as kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"\"\n",
    "X = np.load(DATA_DIR+\"data/description_coque.npy\")[:100000]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en forme  des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la liste des caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'f', '%', ' ', 'T', '&', 'V', '*', ')', '?', 'z', 'Q', '6', ':', 'X', 'C', 'g', 'N', 'I', 'm', 'u', 'U', '-', '3', 'j', 'w', 'ô', '!', 'c', 'ê', 'i', 'b', 'd', 's', 'l', 'h', 'a', 'A', 'L', 'à', 'Y', '8', 'R', 'F', 'é', 'â', 'S', '\"', 'Z', 'D', 'M', 'x', 'J', '\\xa0', 'P', 'k', 'è', 'K', '4', '.', \"'\", '7', ',', 'r', 'v', '5', '2', '1', 't', 'G', '+', 'B', 'y', 'e', 'q', '9', '(', 'E', 'W', '/', '0', 'o', 'H', 'p', 'ç', '…', 'n'] 87\n"
     ]
    }
   ],
   "source": [
    "chars = list(functools.reduce(lambda x,y : x.union(y), [set(x) for x in X], set()))\n",
    "print(chars, len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.extend([\"start\",\"end\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des dictionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = {i:c for i,c in enumerate(chars)}\n",
    "char_to_int = {c:i for i,c in int_to_char.items()}\n",
    "I_START = char_to_int[\"start\"]\n",
    "I_END = char_to_int[\"end\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramètre du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences : 100000, Vocab size : 89, Sequence Length : 198\n"
     ]
    }
   ],
   "source": [
    "SIZE_VOCAB = len(chars)\n",
    "LENGTH_SEQUENCE = len(X[0])+1\n",
    "N_X = 100000\n",
    "print(\"Number of sentences : %d, Vocab size : %d, Sequence Length : %d\" %(N_X, SIZE_VOCAB, LENGTH_SEQUENCE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage des Descriptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input_output_sequence(x, length_sequence, size_vocab, char_to_int_dic, i_start, i_end):\n",
    "    n = x.shape[0]\n",
    "    x_vec = np.zeros((n,length_sequence, size_vocab))\n",
    "    y_vec = np.zeros((n,length_sequence, size_vocab))\n",
    "    x_vec[:,0,i_start] = 1\n",
    "    y_vec[:,-1,i_end] = 1\n",
    "    for ix,x in tqdm(enumerate(x)):\n",
    "        for ic,c in enumerate(x):\n",
    "            c_int = char_to_int_dic[c]\n",
    "            x_vec[ix,ic+1,c_int]=1\n",
    "    y_vec[:,:-1,:] = x_vec[:,1:,:] \n",
    "    return x_vec, y_vec\n",
    "\n",
    "\n",
    "def decode_sequence(x, int_to_char_dic):\n",
    "    seq = []\n",
    "    for i in np.where(x)[1]:\n",
    "        seq.append(int_to_char_dic[i])\n",
    "    return \"\".join(seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelques exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:07, 12644.67it/s]\n"
     ]
    }
   ],
   "source": [
    "x_vec, y_vec = encode_input_output_sequence(X[:N_X], LENGTH_SEQUENCE, SIZE_VOCAB, char_to_int,I_START,I_END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startPour samsung galaxy s2 - i9100 : coque decor drapeau us vintage - Cette coque fantaisie protège et habille votre SAMSUNG Galaxy S2 - i9100. Parfaitement adaptée, elle permet l… Voir la présentation\n",
      "Pour samsung galaxy s2 - i9100 : coque decor drapeau us vintage - Cette coque fantaisie protège et habille votre SAMSUNG Galaxy S2 - i9100. Parfaitement adaptée, elle permet l… Voir la présentationend\n"
     ]
    }
   ],
   "source": [
    "print(decode_sequence(x_vec[8], int_to_char))\n",
    "print(decode_sequence(y_vec[8], int_to_char))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Retrouvez la phrase originale à partir de la phrase encodé. Vérifiez que x et y sont bien les mêmes fonciton d'écalé d'un index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, None, 32)          15616     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 89)          2937      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, None, 89)          0         \n",
      "=================================================================\n",
      "Total params: 18,553\n",
      "Trainable params: 18,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nb_hidden = 32\n",
    "epochs = 10\n",
    "batch_size=128\n",
    "\n",
    "model = km.Sequential()\n",
    "model.add(kl.LSTM(nb_hidden, input_shape=(None, SIZE_VOCAB), return_sequences=True))\n",
    "model.add(kl.TimeDistributed(kl.Dense(SIZE_VOCAB)))\n",
    "model.add(kl.Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 170s 2ms/step - loss: 2.7328\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 169s 2ms/step - loss: 1.4591\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 170s 2ms/step - loss: 0.8730\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 170s 2ms/step - loss: 0.6003\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 170s 2ms/step - loss: 0.4592\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 170s 2ms/step - loss: 0.3845\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 170s 2ms/step - loss: 0.3421\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 170s 2ms/step - loss: 0.3168\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 170s 2ms/step - loss: 0.3013\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 171s 2ms/step - loss: 0.2899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7cb000e390>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "model.fit(x_vec, y_vec, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"data/PLOPP.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startPour apple iphone 4 : coque bumper silicone blanc - Cet étui en silicone rigide protège et habille votre APPLE iPhone 4. Parfaitement adapté, il permet l'accès à toutes les fo… Voir la présentation\n"
     ]
    }
   ],
   "source": [
    "i_test = 0\n",
    "print(decode_sequence(x_vec[i_test], int_to_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "start\n"
     ]
    }
   ],
   "source": [
    "x_pred = np.zeros((1, LENGTH_SEQUENCE, SIZE_VOCAB))\n",
    "print(\"step 0\")\n",
    "x_pred[0,0,I_START] =1\n",
    "x_pred_str = decode_sequence(x_pred[0], int_to_char)\n",
    "print(x_pred_str)\n",
    "for i in range(LENGTH_SEQUENCE-1):\n",
    "    ix = np.argmax(model.predict(x_pred[:,:i+1,:])[0][-1,:])\n",
    "    x_pred[0,i+1,ix] = 1\n",
    "    x_pred_str=decode_sequence(x_pred[0], int_to_char)\n",
    "    print(x_pred_str, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
