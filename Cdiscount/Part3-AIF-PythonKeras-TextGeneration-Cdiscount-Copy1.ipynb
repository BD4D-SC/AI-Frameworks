{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies de l'intelligence Artificielle](https://github.com/wikistat/AI-Frameworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement Naturel du Langage (NLP) : Génération de Texte avec des Réseaux Récurrent. \n",
    "\n",
    "Au cours de ce calepin, nous allons voir comment générer des description de produits à l'aide de Réseaux Récurents et notamment grace aux structure LSTM (Long-Short Term Memory). \n",
    "\n",
    "L'intérêt de cette application est limité. Les descriptions de textes de ce document sont trop pauvres syntaxiquement pour pouvoir juger réellement de la qualité du texte généré. L'intérêt réel de ce calepin est de voir comment les données doivent être mis en forme pour être utilisé dans un réseau recurrent dans un but de génération de texte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importation des librairies utilisées\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import keras.models as km\n",
    "import keras.layers as kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des données\n",
    "\n",
    "La Catégorie de Niveau 3 `COQUE - BUMPER - FACADE TELEPHONE` est la catégorie le plus représenté du jeu de données originale **Cdiscount** avec  2.184.671 déscriptions présentent.  Parmis ces descriptions, 1.761.637 sont composés d'exactement 197 caractères. \n",
    "\n",
    "Nous allons nous servir de ces lignes (ou un sous ensemble de ces lignes, en fonction de la puissance de calcul disponible sur votre machine) pour apprendre un modèle de génération de texte qui permettra de généré automatiquement une nouvelle description de ce type de produit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n",
      "[ \"Pour apple iphone 4 : coque bumper silicone blanc - Cet étui en silicone rigide protège et habille votre APPLE iPhone 4. Parfaitement adapté, il permet l'accès à toutes les fo… Voir la présentation\"\n",
      " \"Pour htc one x : coque noire rigide - Cette coque protège et habille avec sobriété votre HTC ONE X. Parfaitement adaptée, elle permet l'accès à toutes les fonctionnalités de v… Voir la présentation\"\n",
      " \"Pour htc one x : coque blanche rigide - Cette coque protège et habille avec sobriété votre HTC ONE X. Parfaitement adaptée, elle permet l'accès à toutes les fonctionnalités de… Voir la présentation\"]\n"
     ]
    }
   ],
   "source": [
    "N = 100000\n",
    "DATA_DIR = \"\"\n",
    "X = np.load(DATA_DIR+\"data/description_coque.npy\")[:N]\n",
    "print(X.shape)\n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Vérifiez que toutes les séquences sont bien de tailles 197."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nd=197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en forme  des données\n",
    "\n",
    "La génération de texte implique de constuire un réseau `Many-To-One` :\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/wikistat/AI-Frameworks/master/slides/OneToMany.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Ou la prédiction $y_t$ servira d'entrée au réseau au temps $t+1$, i.e : $y_t=x_{t+1}$. \n",
    "\n",
    "Chaque $x_t$ représente ici un caractère de la déscription encodé en One-Hot encoding. Ainsi une description $x$ composé de $N_d$ caractères sera modélisé par une matrice de taille $(N_v\\times N_d)$  $x=[x_1,x_2,...,x_{N_d}]$  ou $x_i \\in \\mathbb{R}^{N_v}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la liste des caractères\n",
    "\n",
    "Afin d'encoder les description sous format 'One-Hot encoding'  nous devons dans un premier temps retrouver la taille $Nv$ de notre vocabulaire constitué de tout les caractères présent dans la description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire : ['x', 'V', ')', 'O', 'X', 'b', '8', ',', 'â', 'à', '!', 'Y', \"'\", 'T', '7', '5', 'n', 'K', 'I', 'ç', '4', '6', 'è', 'P', 'l', 'N', 'é', 'h', 'g', 'q', '.', 'R', 'r', 'B', 'u', ':', 's', 'o', 'y', '9', '+', '?', '0', 'E', '(', 'F', '\"', 'a', 'e', 'H', 'D', 'L', 'w', '-', 'j', 'f', 'k', '*', 'z', '\\xa0', 'ê', 'v', 'd', '/', 'm', 'Q', '2', ' ', 't', 'U', 'C', 'c', 'W', 'S', '…', 'G', 'ô', 'Z', 'i', '3', 'J', 'M', '1', '%', 'A', '&', 'p']\n"
     ]
    }
   ],
   "source": [
    "chars = list(functools.reduce(lambda x,y : x.union(y), [set(x) for x in X], set()))\n",
    "print(\"Vocabulaire : \" +  str(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ajoutons à ce vocabulaire deux indicateur permettant de localiser le début et la fin de chaque description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.extend([\"start\",\"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 89\n"
     ]
    }
   ],
   "source": [
    "Nv = len(chars)\n",
    "print(\"Taille du vocabulaire : %d\" %Nv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des dictionnaires\n",
    "\n",
    "Les dictionnaires `char_to_int` et `int_to_char` permettent respectivement d'encoder une description texte et de décoder un encodage `One-Hot``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = {i:c for i,c in enumerate(chars)}\n",
    "char_to_int = {c:i for i,c in int_to_char.items()}\n",
    "I_START = char_to_int[\"start\"]\n",
    "I_END = char_to_int[\"end\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage des Descriptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante, permet d'encoder une matrice $X\\in \\mathbb{R}^{N \\times N_d}$ constitués de *N* descriptions en une matrice $X_{vec} \\in \\mathbb{R}^{N \\times N_d \\times N_v}$ contenant les description encodées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input_output_sequence(x, length_sequence, size_vocab, char_to_int_dic, i_start, i_end):\n",
    "    n = x.shape[0]\n",
    "    x_vec = np.zeros((n,length_sequence, size_vocab))\n",
    "    y_vec = np.zeros((n,length_sequence, size_vocab))\n",
    "    x_vec[:,0,i_start] = 1\n",
    "    y_vec[:,-1,i_end] = 1\n",
    "    for ix,x in tqdm(enumerate(x)):\n",
    "        for ic,c in enumerate(x):\n",
    "            c_int = char_to_int_dic[c]\n",
    "            x_vec[ix,ic+1,c_int]=1\n",
    "    y_vec[:,:-1,:] = x_vec[:,1:,:] \n",
    "    return x_vec, y_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:18, 5519.12it/s]\n"
     ]
    }
   ],
   "source": [
    "X_vec, Y_vec = encode_input_output_sequence(X[:N], Nd+1, Nv, char_to_int,I_START,I_END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 198, 89)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Retrouvez la phrase originale de la phrase test affiché ci-dessous à partir de la phrase encodé. Vérifiez que x et y sont bien les mêmes descriptions seulement décalées d'un index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour htc one mini : coque sur mesure decor pluie d'etoiles - Cette coque fantaisie protège et habille votre HTC ONE Mini. Parfaitement adaptée, elle permet l'accès à toutes le… Voir la présentation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"startPour htc one mini : coque sur mesure decor pluie d'etoiles - Cette coque fantaisie protège et habille votre HTC ONE Mini. Parfaitement adaptée, elle permet l'accès à toutes le… Voir la présentation\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_test = 50\n",
    "print(X[50])\n",
    "#%load solution/3_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage\n",
    "\n",
    "Nous allons maintenant définir notre modèle récurrent afin de générer notre modèle de prédiction. \n",
    "\n",
    "Prenez le temps de bien comprendre toutes les fonctions et arguments utilisés pour construire ce modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, None, 32)          15616     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, None, 89)          2937      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, None, 89)          0         \n",
      "=================================================================\n",
      "Total params: 18,553\n",
      "Trainable params: 18,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nb_hidden = 32\n",
    "epochs = 20\n",
    "batch_size= 128\n",
    "\n",
    "model = km.Sequential()\n",
    "model.add(kl.LSTM(nb_hidden, input_shape=(None, Nv), return_sequences=True))\n",
    "model.add(kl.TimeDistributed(kl.Dense(Nv)))\n",
    "model.add(kl.Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "model.fit(x_vec, y_vec, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Pourquoi est-ce la `categorical_crossentropy` qui est utilisés comme fonction de loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération de Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_test = 0\n",
    "print(decode_sequence(x_vec[i_test], int_to_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.zeros((1, LENGTH_SEQUENCE, SIZE_VOCAB))\n",
    "print(\"step 0\")\n",
    "x_pred[0,0,I_START] =1\n",
    "x_pred_str = decode_sequence(x_pred[0], int_to_char)\n",
    "print(x_pred_str)\n",
    "for i in range(LENGTH_SEQUENCE-1):\n",
    "    ix = np.argmax(model.predict(x_pred[:,:i+1,:])[0][-1,:])\n",
    "    x_pred[0,i+1,ix] = 1\n",
    "    x_pred_str=decode_sequence(x_pred[0], int_to_char)\n",
    "    print(x_pred_str, end=\"\\r\")\n",
    "print(x_pred_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:DeepLearning]",
   "language": "python",
   "name": "conda-env-DeepLearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
