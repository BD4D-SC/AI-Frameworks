{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies de l'intelligence Artificielle](https://github.com/wikistat/AI-Frameworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" width=400, style=\"max-width: 150px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" width=400,  style=\"float:right;  display: inline\" alt=\"IMT\"/> </a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data : Cdiscount's product description.\n",
    "\n",
    "This dataset has been released from Cdiscount for a data competition (type kaggle) on the french website [datascience.net](https://www.datascience.net/fr/challenge). <br>\n",
    "The test dataset of this competition has not been released, so we used a subset of 1M producted of the original train dataset(+15M rows) all along the **Natural Language Processing** lab.<br>\n",
    "The objective of this competition was to classify the text description of various product into various categories that compose the navigation tree of Cdiscount website. It is composed of 4,733 categories organized within 44 meta categories. <br>\n",
    "\n",
    "The objective of this lab is not win the competition so we will only used the meta-categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Words embedding. Application to text classification and semi-supervised learning.\n",
    "\n",
    "In this first notebook we study three words embedding methods:\n",
    "\n",
    "* [Word2Vec](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "* [FastText](https://arxiv.org/pdf/1607.04606.pdf)\n",
    "* [Glove](https://nlp.stanford.edu/pubs/glove.pdf)\n",
    "\n",
    "We for each of these three method we will:\n",
    "\n",
    "* Study their characteristics\n",
    "* Explore the embedding they produces\n",
    "* Check how they perform on classification problems\n",
    "* Check how they can overcome problem with few labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Importation des librairies utilisées\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import itertools\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn.model_selection as sms\n",
    "from solution.clean import CleanText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We download the train and test data and generate the same cleaned columns and the same train/validation split than part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 173/1000 [00:00<00:00, 1728.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Clean 1000 lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2055.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset is composed of 1000 lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorie1</th>\n",
       "      <th>Categorie2</th>\n",
       "      <th>Categorie3</th>\n",
       "      <th>Description</th>\n",
       "      <th>Libelle</th>\n",
       "      <th>Marque</th>\n",
       "      <th>Description_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFORMATIQUE</td>\n",
       "      <td>CONNECTIQUE - ALIMENTATION</td>\n",
       "      <td>BATTERIE</td>\n",
       "      <td>Batterie Acer Aspire One 751H-52Yr - Li-Ion 11...</td>\n",
       "      <td>Batterie Acer Aspire One 751H-52Yr</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>batter acer aspir one h yr li ion v mah wh noi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>ACCESSOIRE TELEPHONE</td>\n",
       "      <td>COQUE - BUMPER - FACADE TELEPHONE</td>\n",
       "      <td>Coque rigide Bleu lagon pour ALCATEL OT / 6033...</td>\n",
       "      <td>Coque rigide Bleu lagon pour ALCATEL OT / 6033 …</td>\n",
       "      <td>MUZZANO</td>\n",
       "      <td>coqu rigid bleu lagon alcatel ot motif drapeau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>ACCESSOIRE TELEPHONE</td>\n",
       "      <td>COQUE - BUMPER - FACADE TELEPHONE</td>\n",
       "      <td>Facades et coques CELLULAR LINE SHCKGALS 3 MIN...</td>\n",
       "      <td>Facades et coques CELLULAR LINE SHCKGALS 3 MINIP</td>\n",
       "      <td>CELLULAR LINE</td>\n",
       "      <td>facad coqu cellular lin shckgal minip marqu ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>ACCESSOIRE TELEPHONE</td>\n",
       "      <td>COQUE - BUMPER - FACADE TELEPHONE</td>\n",
       "      <td>Coque meteore TPU  LG Nexus 4 / E960</td>\n",
       "      <td>Coque meteore TPU  LG Nexus 4 / E960</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>coqu meteor tpu lg nexus e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TELEPHONIE - GPS</td>\n",
       "      <td>ACCESSOIRE TELEPHONE</td>\n",
       "      <td>COQUE - BUMPER - FACADE TELEPHONE</td>\n",
       "      <td>Coque souple Transparente pour LG G FLEX D959 ...</td>\n",
       "      <td>Coque souple Transparente pour LG G FLEX D959 m…</td>\n",
       "      <td>MUZZANO</td>\n",
       "      <td>coqu soupl transparent lg g flex motif keep ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Categorie1                  Categorie2  \\\n",
       "0      INFORMATIQUE  CONNECTIQUE - ALIMENTATION   \n",
       "1  TELEPHONIE - GPS        ACCESSOIRE TELEPHONE   \n",
       "2  TELEPHONIE - GPS        ACCESSOIRE TELEPHONE   \n",
       "3  TELEPHONIE - GPS        ACCESSOIRE TELEPHONE   \n",
       "4  TELEPHONIE - GPS        ACCESSOIRE TELEPHONE   \n",
       "\n",
       "                          Categorie3  \\\n",
       "0                           BATTERIE   \n",
       "1  COQUE - BUMPER - FACADE TELEPHONE   \n",
       "2  COQUE - BUMPER - FACADE TELEPHONE   \n",
       "3  COQUE - BUMPER - FACADE TELEPHONE   \n",
       "4  COQUE - BUMPER - FACADE TELEPHONE   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Batterie Acer Aspire One 751H-52Yr - Li-Ion 11...   \n",
       "1  Coque rigide Bleu lagon pour ALCATEL OT / 6033...   \n",
       "2  Facades et coques CELLULAR LINE SHCKGALS 3 MIN...   \n",
       "3               Coque meteore TPU  LG Nexus 4 / E960   \n",
       "4  Coque souple Transparente pour LG G FLEX D959 ...   \n",
       "\n",
       "                                            Libelle         Marque  \\\n",
       "0                Batterie Acer Aspire One 751H-52Yr         AUCUNE   \n",
       "1  Coque rigide Bleu lagon pour ALCATEL OT / 6033 …        MUZZANO   \n",
       "2  Facades et coques CELLULAR LINE SHCKGALS 3 MINIP  CELLULAR LINE   \n",
       "3              Coque meteore TPU  LG Nexus 4 / E960         AUCUNE   \n",
       "4  Coque souple Transparente pour LG G FLEX D959 m…        MUZZANO   \n",
       "\n",
       "                                 Description_cleaned  \n",
       "0  batter acer aspir one h yr li ion v mah wh noi...  \n",
       "1  coqu rigid bleu lagon alcatel ot motif drapeau...  \n",
       "2  facad coqu cellular lin shckgal minip marqu ag...  \n",
       "3                         coqu meteor tpu lg nexus e  \n",
       "4  coqu soupl transparent lg g flex motif keep ca...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = CleanText()\n",
    "data = pd.read_csv(\"data/cdiscount_train.csv.zip\",sep=\",\", nrows=1000)\n",
    "ct.clean_df_column(data, \"Description\", \"Description_cleaned\")\n",
    "print(\"The train dataset is composed of %d lines\" %data.shape[0])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = sms.train_test_split(data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 177/50000 [00:00<00:28, 1760.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Clean 50000 lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:22<00:00, 2202.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset is composed of 50000 lines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categorie1</th>\n",
       "      <th>Categorie2</th>\n",
       "      <th>Categorie3</th>\n",
       "      <th>Description</th>\n",
       "      <th>Libelle</th>\n",
       "      <th>Marque</th>\n",
       "      <th>Description_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRICOLAGE - OUTILLAGE - QUINCAILLERIE</td>\n",
       "      <td>ELECTRICITE  DOMOTIQUE</td>\n",
       "      <td>MULTIPRISE - RALLONGE - ENROULEUR</td>\n",
       "      <td>Rallonge CEE avec inverseur de phase 25 m 16 A...</td>\n",
       "      <td>Rallonge CEE avec inverseur de phase 25 m 16 A</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>rallong ce inverseur phas rallong ce haut qual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DECO - LINGE - LUMINAIRE</td>\n",
       "      <td>OBJET DE DECORATION - BIBELOT</td>\n",
       "      <td>BUSTE - MANNEQUIN</td>\n",
       "      <td>Sun d’koh - Buste de Bouddha sur socle - cimen...</td>\n",
       "      <td>Sun d’koh - Buste de Bouddha sur socle - ciment…</td>\n",
       "      <td>SUN D’KOH</td>\n",
       "      <td>sun dkoh bust bouddh socl ciment cm tet bouddh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HYGIENE - BEAUTE - PARFUM</td>\n",
       "      <td>NAIL ART</td>\n",
       "      <td>STICKERS - AUTOCOLLANT - STRASS - PAILLETTES -...</td>\n",
       "      <td>La planche contient 24 motifs Support : ongle ...</td>\n",
       "      <td>STICKERS COLLIER STRASS FLEUR ONGLE ADHESIF</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>planch contient motif support ongle naturel ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIBRAIRIE</td>\n",
       "      <td>AUTRES LIVRES</td>\n",
       "      <td>AUTRES LIVRES</td>\n",
       "      <td>De Blodwenn Mauffret aux éditions IBIS ROUGE</td>\n",
       "      <td>LE CARNAVAL DE CAYENNE</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>blodwen mauffret edit ibis roug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VETEMENTS - LINGERIE</td>\n",
       "      <td>ACCESSOIRE MODE</td>\n",
       "      <td>CHAPEAU - BOB</td>\n",
       "      <td>Chapeau  - Casquette béret Modèle féminin et t...</td>\n",
       "      <td>Chapeau ... TU</td>\n",
       "      <td>AUCUNE</td>\n",
       "      <td>chapeau casquet beret model feminin tendanc mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Categorie1                     Categorie2  \\\n",
       "0  BRICOLAGE - OUTILLAGE - QUINCAILLERIE        ELECTRICITE  DOMOTIQUE   \n",
       "1               DECO - LINGE - LUMINAIRE  OBJET DE DECORATION - BIBELOT   \n",
       "2              HYGIENE - BEAUTE - PARFUM                       NAIL ART   \n",
       "3                              LIBRAIRIE                  AUTRES LIVRES   \n",
       "4                  VETEMENTS - LINGERIE                 ACCESSOIRE MODE   \n",
       "\n",
       "                                          Categorie3  \\\n",
       "0                  MULTIPRISE - RALLONGE - ENROULEUR   \n",
       "1                                  BUSTE - MANNEQUIN   \n",
       "2  STICKERS - AUTOCOLLANT - STRASS - PAILLETTES -...   \n",
       "3                                      AUTRES LIVRES   \n",
       "4                                     CHAPEAU - BOB    \n",
       "\n",
       "                                         Description  \\\n",
       "0  Rallonge CEE avec inverseur de phase 25 m 16 A...   \n",
       "1  Sun d’koh - Buste de Bouddha sur socle - cimen...   \n",
       "2  La planche contient 24 motifs Support : ongle ...   \n",
       "3       De Blodwenn Mauffret aux éditions IBIS ROUGE   \n",
       "4  Chapeau  - Casquette béret Modèle féminin et t...   \n",
       "\n",
       "                                            Libelle     Marque  \\\n",
       "0    Rallonge CEE avec inverseur de phase 25 m 16 A     AUCUNE   \n",
       "1  Sun d’koh - Buste de Bouddha sur socle - ciment…  SUN D’KOH   \n",
       "2       STICKERS COLLIER STRASS FLEUR ONGLE ADHESIF     AUCUNE   \n",
       "3                            LE CARNAVAL DE CAYENNE     AUCUNE   \n",
       "4                                    Chapeau ... TU     AUCUNE   \n",
       "\n",
       "                                 Description_cleaned  \n",
       "0  rallong ce inverseur phas rallong ce haut qual...  \n",
       "1  sun dkoh bust bouddh socl ciment cm tet bouddh...  \n",
       "2  planch contient motif support ongle naturel ca...  \n",
       "3                    blodwen mauffret edit ibis roug  \n",
       "4  chapeau casquet beret model feminin tendanc mo...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"data/cdiscount_test.csv.zip\",sep=\",\")\n",
    "ct.clean_df_column(data_test, \"Description\", \"Description_cleaned\")\n",
    "print(\"The train dataset is composed of %d lines\" %data_test.shape[0])\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "In this part, we will generate`Word2Vec` model thanks to the [**gensim**](https://radimrehurek.com/gensim/index.html) python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Word2Vec model\n",
    "\n",
    "La fonction `gensim.models.Word2Vec`qui permet de construire des modèle Word2Vec prend en entrée une liste de tokens. On tranformer donc nos données dans un premier temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array_token = [line.split(\" \") for line in train_array]\n",
    "valid_array_token = [line.split(\" \") for line in valid_array]\n",
    "train_array_token[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction contient un grand nombre d' [arguments](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec). Le but de ce TP n'est pas d'optimiser les paramètres de ce modèle mais de les comprendre. Nous allons donc fixer quelques arguments par défault : \n",
    "\n",
    "* Features_dimension = 300 : Dimension de l'espace des features (d'*embedding*) qui sera crée.\n",
    "* hs = 0\n",
    "* negative = 10\n",
    "\n",
    "**Q** A quoi servent les arguments *hs* et *negative*? Quels influences ces arguments ont sur le modèle avec les valeurs définies ici?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_dimension = 300\n",
    "hs = 0\n",
    "negative = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer deux modèles :\n",
    "\n",
    "* Un modèle **skip-sgram**, sg = 1\n",
    "* Un modèle **CBOW**, sg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = 1\n",
    "print(\"Start learning skip-gram Word2Vec\")\n",
    "ts = time.time()\n",
    "model_sg = gensim.models.Word2Vec(train_array_token, sg=sg, hs=hs, negative=negative, min_count=1, size=Features_dimension)\n",
    "te = time.time()\n",
    "t_learning = te-ts\n",
    "print(\"Learning time : %.2f seconds Word2Vec\" %t_learning)\n",
    "\n",
    "\n",
    "sg = 0\n",
    "print(\"Start learning CBOW Word2Vec\")\n",
    "ts = time.time()\n",
    "model_cbow = gensim.models.Word2Vec(train_array_token, sg=sg, hs=hs, negative=negative, min_count=1, size=Features_dimension)\n",
    "te = time.time()\n",
    "t_learning = te-ts\n",
    "print(\"Learning time : %.2f seconds Word2Vec\" %t_learning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que dire du temps d'apprentissage de ces deux modèles? D'ou vient cette différence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Trained Model\n",
    "\n",
    "Comme pour les réseaux de convolution, des modèles pré-entrainés de Word2Vec éxistent également. \n",
    "Le plus célèbre et le plus utilisé étant [`GoogleNewsVectors`](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit) appris sur plus de 100 milliard de mots à partir des articles de GoogleNews. Cependant ce modèle est en anglais, et n'est donc )as utile ici.\n",
    "\n",
    "\n",
    "On utilisera des modèle appris dans le projet suivant [https://github.com/Kyubyong/wordvectors](https://github.com/Kyubyong/wordvectors) appris sur 1Giga d'articles de wikipedia en mode **Skip-Gram*\n",
    "\n",
    "Vous pouvez télécharger ce modèle en suivant ce [lien](https://drive.google.com/file/d/0B0ZXk88koS2KM0pVTktxdG15TkE/view). Dezipez-le puis téléchargez le modèle en indiquant la direction du fichier \"fr/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_online_dir = \"data/fr/fr.bin\"\n",
    "#model_online_dir = \"ACOMPLETER/fr.bin\"\n",
    "model_online = gensim.models.Word2Vec.load(model_online_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propriété du modèle\n",
    "\n",
    "Nous allons maintenant comparer quelques propriétés de chacun des trois modèles à notre disposition (*CBOW*, *Skip-Gram* et le modèle *online*)\n",
    "\n",
    "Les modèles que nous avons appris l'ont été sur les mots *racinisé*. Ainsi, nous allons avoir besoin de la racine des mots pour tester les différentes propriétés du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "stemmer=nltk.stem.SnowballStemmer('french')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most similar world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `most_similar` de **gensim** permet de retrouver les mots les plus proches à un ou une combinaison de mots données en argument.\n",
    "\n",
    "**Q** A l'aide de la [documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar) répondez aux questions suivantes. Quelle est la mesure de similarité utilisée? Dans quel espace est-elle utilisé? Comment fonctionne la fonction lorsque plusieurs mots sont passés en paramètres? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1 mot\n",
    "\n",
    "\n",
    "**Exercice** Pour chacun de ces trois modèles, affichez les sorties de la fonction 'most_similar' pour le mot *homme*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/2_3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comparez la qualité de prévision des modèles que nous avons entrainés sur le jeu de données 'Cdiscount' avec celui appris online. Que pouvez-vous en dire? \n",
    "\n",
    "**Q** Comparez les prévisions des deux modèles que nous avons entrainés. Que pouvez-vous en dire?\n",
    "\n",
    "**Exercice** Affichez maintenant les sorties de la fonction 'most_similar' pour le mot *femme*. \n",
    "\n",
    "**Exercice** Affichez les sorties de la fonction 'most_similar' pour des mots propre au jeu de données (ex. *xbox*, *pantalon*,..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combinaison de mots\n",
    "\n",
    "**Exercice** Pour chacun de ces trois modèles, affichez les sorties de la fonction 'most_similar' pour l'opération suivante : *roi* + *femme* - *homme* à l'aide des arguments *positive* et *negative* de la fonction. Commentez encore une fois la qualité de sortie des différents modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/2_4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** Testez d'autres combinaisons si vous le souhaitez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict output word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `predict_output_word` de **gensim** permet de retrouver les mots prédit par le modèle à partir d'un mot ou d'une combinaison de mots données en argument.\n",
    "\n",
    "**Exercice**  Affichez la prédiction des trois modèles pour des mots/combinaisons de mots communs (*homme*, *femme*) ou plus propre au jeu de données étudiés. (*coque*-*de*-*téléphone*)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solution/2_5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Features\n",
    "\n",
    "Nous allons maintenant créer des matrices de features à partir des modèles de **Word2Vec** générés précédemment dans un but de prédiction. \n",
    "\n",
    "La modèles créés permettent d'obtenir pour chaque mot `x`, sa représentation dans l'espace d'embeddings de la manière suivante : \n",
    "\n",
    "*x_feature = model_word2vec[x]* \n",
    "\n",
    "Dans notre problématique, les individus que nous cherchons à classer sont des descriptions représentées par une liste de token à l'issue du nettoyage du calepin précédent.  Il exsite donc plusieurs façon de représenter ces individus à l'aide de modèle **Word2Vec**. \n",
    "\n",
    "1. Moyenne des vecteurs dans l'espace des features des différents mots/token de la description.\n",
    "2. Moyenne pondérées des vecteurs dans l'espace des features des différents mots/token de la description en fonction de l'occurence de chacun de ces mots/tokens dans la description.\n",
    "3. Moyenne pondérées par des poids calculés à l'aide du TF-IDF.\n",
    "4. etc...\n",
    "\n",
    "C'est la seconde solution qui sera utilisée ici. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions détaillées ci-dessous permettent de :\n",
    "    \n",
    "* `get_features_mean` : retourne le vecteur moyen dans l'espace d'embedding, des projections des mots/tokens composant *lines*\n",
    "* `get_matrix_features_means` : applique la fonction `get_features_mean` sur tous les éléments de la matrice *X*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_mean(lines, model, f_size):\n",
    "    features = [model[x] for x  in lines if x in model]\n",
    "    if features == []:   \n",
    "        fm =np.ones(f_size)\n",
    "    else :\n",
    "        fm = np.mean(features,axis=0)\n",
    "    return fm\n",
    "\n",
    "def get_matrix_features_means(X, model, f_size):\n",
    "    X_embedded_ = list(map(lambda x : get_features_mean(x, model, f_size), X))\n",
    "    X_embedded = np.vstack(X_embedded_)\n",
    "    return X_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "X_embedded_train_cbow = get_matrix_features_means(train_array_token, model_cbow, Features_dimension)\n",
    "te = time.time()\n",
    "t_build = te-ts\n",
    "#np.save(embedded_train_dir, X_embedded_train)\n",
    "print(\"Time conversion : %d seconds\"%t_build)\n",
    "print(\"Shape Matrix : (%d,%d)\"%X_embedded_train_cbow.shape)\n",
    "np.save(DATA_OUTPUT_DIR +\"/embedded_train_cbow\", X_embedded_train_cbow)\n",
    "\n",
    "ts = time.time()\n",
    "X_embedded_valid_cbow = get_matrix_features_means(valid_array_token, model_cbow, Features_dimension)\n",
    "te = time.time()\n",
    "t_build = te-ts\n",
    "#np.save(embedded_train_dir, X_embedded_train)\n",
    "print(\"Time conversion : %d seconds\"%t_build)\n",
    "print(\"Shape Matrix : (%d,%d)\"%X_embedded_valid_cbow.shape)\n",
    "np.save(DATA_OUTPUT_DIR +\"/embedded_valid_cbow\", X_embedded_valid_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "X_embedded_train_sg = get_matrix_features_means(train_array_token, model_sg, Features_dimension)\n",
    "te = time.time()\n",
    "t_build = te-ts\n",
    "#np.save(embedded_train_dir, X_embedded_train)\n",
    "print(\"Time conversion : %d seconds\"%t_build)\n",
    "print(\"Shape Matrix : (%d,%d)\"%X_embedded_train_sg.shape)\n",
    "np.save(DATA_OUTPUT_DIR +\"/embedded_train_sg\", X_embedded_train_sg)\n",
    "\n",
    "ts = time.time()\n",
    "X_embedded_valid_sg = get_matrix_features_means(valid_array_token, model_sg, Features_dimension)\n",
    "te = time.time()\n",
    "t_build = te-ts\n",
    "#np.save(embedded_train_dir, X_embedded_train)\n",
    "print(\"Time conversion : %d seconds\"%t_build)\n",
    "print(\"Shape Matrix : (%d,%d)\"%X_embedded_valid_sg.shape)\n",
    "np.save(DATA_OUTPUT_DIR +\"/embedded_valid_sg\", X_embedded_valid_sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid_clean = pd.read_csv(\"data/cdiscount_valid_clean.csv\").fillna(\"\")\n",
    "data_train_clean = pd.read_csv(\"data/cdiscount_train_clean.csv\").fillna(\"\")\n",
    "\n",
    "train_array_token_nostem = [line.split(\" \") for line in data_train_clean[\"Description\"].values]\n",
    "valid_array_token_nostem = [line.split(\" \") for line in data_valid_clean[\"Description\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "X_embedded_train_online = get_matrix_features_means(train_array_token_nostem, model_online, Features_dimension)\n",
    "te = time.time()\n",
    "t_build = te-ts\n",
    "#np.save(embedded_train_dir, X_embedded_train)\n",
    "print(\"Time conversion : %d seconds\"%t_build)\n",
    "print(\"Shape Matrix : (%d,%d)\"%X_embedded_train_online.shape)\n",
    "np.save(DATA_OUTPUT_DIR +\"/embedded_train_online\", X_embedded_train_online)\n",
    "\n",
    "ts = time.time()\n",
    "X_embedded_valid_online = get_matrix_features_means(valid_array_token_nostem, model_online, Features_dimension)\n",
    "te = time.time()\n",
    "t_build = te-ts\n",
    "#np.save(embedded_train_dir, X_embedded_train)\n",
    "print(\"Time conversion : %d seconds\"%t_build)\n",
    "print(\"Shape Matrix : (%d,%d)\"%X_embedded_valid_online.shape)\n",
    "np.save(DATA_OUTPUT_DIR +\"/embedded_valid_online\", X_embedded_valid_online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {
    "height": "279px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
